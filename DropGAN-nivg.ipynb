{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mn104.mcl.weizmann.ac.il\u001b[m  Wed Jan 20 19:22:16 2021  \u001b[1m\u001b[30m450.80.02\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 27'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2508\u001b[m / \u001b[33m11019\u001b[m MB | \u001b[1m\u001b[30mbenf\u001b[m:\u001b[36mpython\u001b[m(\u001b[33m2505M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m11019\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat -cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "import Resizer\n",
    "from image import imread, imwrite, imshow, to_numpy\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2pt(arr):\n",
    "    return torch.tensor(arr).permute(2, 0, 1).unsqueeze(0).contiguous()\n",
    "\n",
    "def pt2np(tensor):\n",
    "    return to_numpy(tensor.squeeze(0).permute(1, 2, 0))\n",
    "\n",
    "def bm3d_denoise(input, sigma):\n",
    "    return np2pt(bm3d(pt2np(input), sigma)).to(device=input.device, dtype=input.dtype)\n",
    "\n",
    "def imread2pt(path, d=None, **kwargs):\n",
    "    image = imread(path, **kwargs)\n",
    "    image = np2pt(image)\n",
    "    # image = torch.tensor(imread(path, **kwargs)).permute(2, 0, 1).unsqueeze(0)\n",
    "    if d is not None:\n",
    "        image = shave_image(image, d)\n",
    "    return image.contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pyramids_aux(img_torch, num_layers,ratio, print_):\n",
    "    max_layer = num_layers\n",
    "    pyr = []\n",
    "    ratio = ratio\n",
    "    if isinstance(ratio, float) or isinstance(ratio, int):\n",
    "        ratio = (ratio, ratio)\n",
    "    curr_img = img_torch\n",
    "    pyr.append(curr_img)\n",
    "    for j in range(max_layer):\n",
    "        if print_:\n",
    "            print(curr_img.shape)\n",
    "            imshow(curr_img)\n",
    "        rsizer = Resizer.Resizer(curr_img.shape, ratio, [1, img_torch.shape[1], np.ceil(img_torch.shape[2]*(ratio[0])**(j+1)), np.ceil(img_torch.shape[3]*(ratio[1])**(j+1))]).cuda()\n",
    "        curr_img = rsizer(curr_img)\n",
    "        pyr.append(curr_img)\n",
    "        \n",
    "    return pyr\n",
    "\n",
    "def get_pyramid(file, degradation, sigma, num_layers, ratio, print_=True):\n",
    "    gt = np.expand_dims(imread(file, pt=False), 0)\n",
    "    gt = torch.tensor(gt).contiguous().permute(0, 3, 1, 2).detach().cuda()\n",
    "    return get_pyramids_aux(gt, num_layers,ratio, print_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIV = 100\n",
    "\n",
    "def patch2im(input, w, h, patch_size=7):\n",
    "    out = input.transpose(1,2)\n",
    "    normalize = torch.ones_like(out)\n",
    "    normalize = normalize.transpose(1,2)\n",
    "    fold = torch.nn.functional.fold(\n",
    "        input, \n",
    "        output_size=(w, h), \n",
    "        kernel_size=(patch_size, patch_size)\n",
    "    )\n",
    "\n",
    "    norm = torch.nn.functional.fold(\n",
    "        normalize,\n",
    "        output_size=(w, h),\n",
    "        kernel_size=(patch_size, patch_size),\n",
    "    )\n",
    "\n",
    "    return fold/norm\n",
    "\n",
    "\n",
    "def _calc_dist_l2(X, Y):\n",
    "    Y = Y.transpose(0, 1)\n",
    "    X2 = X.pow(2).sum(1, keepdim=True)\n",
    "    Y2 = Y.pow(2).sum(0, keepdim=True)\n",
    "    XY = X @ Y\n",
    "    return X2 - (2 * XY) + Y2\n",
    "\n",
    "\n",
    "def build_image(input_img, index_imgs, ref_imgs, patch_size=7):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold(input_img)\n",
    "    for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold(ind_img)\n",
    "            ref_patches = unfold(ref_img)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold(ind_img)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold(ref_img)], dim=-1)\n",
    "            \n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#                 print(start_patch, end_patch, dist_mat.shape)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0))\n",
    "    return patch2im(out_patches.unsqueeze(0).permute(0,2,1), input_img.shape[-2], input_img.shape[-1], patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_image_generation(src_pyr, dst_pyr, patch_size=7, top_level=9):\n",
    "    start = time.time()\n",
    "    new_im = dst_pyr[top_level] + torch.randn_like(dst_pyr[top_level])*0.75#new_pyr[9].clone()#\n",
    "    for l in range(top_level,-1,-1): \n",
    "        num_iters = 1 if l == top_level else 10\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "            if l == top_level:\n",
    "                new_im = build_image(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=7)\n",
    "            else:\n",
    "                new_im = build_image(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=7)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "    imshow(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1140e6088044188c81d5edd2d8828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xf7\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x001\\xd8\\x9a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.99[s]\n",
      "ratio=[1, 1] k=0 time=1992.02ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23605d028a04432993d2b2887b63be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xf7\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x001\\xd8\\x9a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66be727f03c40d6b19b15d8810d81c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xf7\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x001\\xd8\\x9a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.98[s]\n",
      "ratio=[1, 1] k=1 time=1978.65ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29e693a42824cf68fb4e1a7438ab424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xf7\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x001\\xd8\\x9a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5f8142d3814233a33fc3ed03c773ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc6\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\xb6\\xe9s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.70[s]\n",
      "ratio=[1, 0.8] k=0 time=1699.28ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588a376ad6574114b3e72ff1feb64745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc6\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\xb6\\xe9s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644ed8cbd94846cd9766b33b624ead22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc6\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\xb6\\xe9s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.70[s]\n",
      "ratio=[1, 0.8] k=1 time=1704.36ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf560b03ed3481a8e7a96798690ea13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc6\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\xb6\\xe9s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6814387add1b4b67ad318162c0c02cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xba\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00Z\\x9c\\x16…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.65[s]\n",
      "ratio=[1, 0.75] k=0 time=1654.64ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316745a6f789452ab422c677e98c2bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xba\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00Z\\x9c\\x16…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c30f7d3ac0545c788009c59a52eb1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xba\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00Z\\x9c\\x16…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.65[s]\n",
      "ratio=[1, 0.75] k=1 time=1650.26ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3456636320b4f6d955b3d484fcad54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xba\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00Z\\x9c\\x16…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6237789c8ab74eb6a320cc1609010d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00S\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x91k0\\x8e\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.92[s]\n",
      "ratio=[1, 0.3333333333333333] k=0 time=919.04ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dc30c065c3499e97e7d1be305c8407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00S\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x91k0\\x8e\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c5a9f5ca1e436fbc87c0670fc3c423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00S\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x91k0\\x8e\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.92[s]\n",
      "ratio=[1, 0.3333333333333333] k=1 time=917.99ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c73515036e14ccda2ed839952ee29eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00S\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x91k0\\x8e\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e681c209f64876b8af2e53c96d86d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x015\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x8c\\x1c\\x9b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.33[s]\n",
      "ratio=[1, 1.25] k=0 time=2334.41ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c73ba0e5f1349fc898a46bc4577ae5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x015\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x8c\\x1c\\x9b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6ff46861545568f3fa4e441e002fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x015\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x8c\\x1c\\x9b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.34[s]\n",
      "ratio=[1, 1.25] k=1 time=2337.40ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933fd35cde2f4b61a1a831a3d3014d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x015\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00\\x8c\\x1c\\x9b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b996025da149268f81bb19b5eff93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xee\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00+\\xed\\xef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.50[s]\n",
      "ratio=[1, 2] k=0 time=3498.42ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19ee7b67b2b4a7f889294fca7363781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xee\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00+\\xed\\xef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c30f46d3d94d748b9317b722ad2fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xee\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00+\\xed\\xef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.50[s]\n",
      "ratio=[1, 2] k=1 time=3499.69ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df6c5320b394ecfb4660b5ea25810ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xee\\x00\\x00\\x00\\x9b\\x08\\x02\\x00\\x00\\x00+\\xed\\xef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyr = get_pyramid('/home/nivg/data/mountains.jpg', None, 0, 15, 0.75, print_=False) \n",
    "pyr=pyr[3:]\n",
    "for ratio in ([[1,1],[1,4/5],[1,3/4],[1,1/3],[1,5/4],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        start = time.time()\n",
    "        out = new_image_generation(pyr, dst_pyr)\n",
    "        print('ratio=%s' % (ratio,), 'k=%d' % (k,), 'time=%.2fms' % (1000 * (time.time() - start),))\n",
    "        imshow(out)\n",
    "        \n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIV = 100\n",
    "\n",
    "def patch2im(input, w, h, patch_size=7):\n",
    "    out = input.transpose(1,2)\n",
    "    normalize = torch.ones_like(out)\n",
    "    normalize = normalize.transpose(1,2)\n",
    "    fold = torch.nn.functional.fold(\n",
    "        input, \n",
    "        output_size=(w, h), \n",
    "        kernel_size=(patch_size, patch_size)\n",
    "    )\n",
    "\n",
    "    norm = torch.nn.functional.fold(\n",
    "        normalize,\n",
    "        output_size=(w, h),\n",
    "        kernel_size=(patch_size, patch_size),\n",
    "    )\n",
    "\n",
    "    return fold/norm\n",
    "\n",
    "\n",
    "def _calc_dist_l2(X, Y):\n",
    "    Y = Y.transpose(0, 1)\n",
    "    X2 = X.pow(2).sum(1, keepdim=True)\n",
    "    Y2 = Y.pow(2).sum(0, keepdim=True)\n",
    "    XY = X @ Y\n",
    "    return X2 - (2 * XY) + Y2\n",
    "\n",
    "\n",
    "def build_image(input_img, index_imgs, ref_imgs, patch_size=7):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold(input_img)\n",
    "    for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold(ind_img)\n",
    "            ref_patches = unfold(ref_img)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold(ind_img)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold(ref_img)], dim=-1)\n",
    "            \n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#                 print(start_patch, end_patch, dist_mat.shape)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0))\n",
    "    return patch2im(out_patches.unsqueeze(0).permute(0,2,1), input_img.shape[-2], input_img.shape[-1], patch_size)\n",
    "\n",
    "def build_image_bidirectional(input_img, index_imgs, ref_imgs, patch_size=7, eps=1):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold(input_img)\n",
    "    for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold(ind_img)\n",
    "            ref_patches = unfold(ref_img)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold(ind_img)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold(ref_img)], dim=-1)\n",
    "            \n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "            dist_mat /= patch_size*patch_size*3\n",
    "            if start_patch < end_patch:\n",
    "                dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        dist_mat /= patch_size*patch_size*3\n",
    "        dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0))\n",
    "    return patch2im(out_patches.unsqueeze(0).permute(0,2,1), input_img.shape[-2], input_img.shape[-1], patch_size)\n",
    "\n",
    "\n",
    "\n",
    "def build_image_no_dc(input_img, index_imgs, ref_imgs, patch_size=7):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold(input_img)\n",
    "    for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold(ind_img)\n",
    "            ref_patches = unfold(ref_img)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold(ind_img)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold(ref_img)], dim=-1)\n",
    "    index_patches = index_patches - index_patches.mean(1, keepdim=True)\n",
    "    ref_patches = ref_patches - ref_patches.mean(1, keepdim=True)\n",
    "    dc_in = in_patches.mean(1, keepdim=True)\n",
    "    in_patches = in_patches - dc_in\n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#                 print(start_patch, end_patch, dist_mat.shape)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0))\n",
    "    return patch2im(out_patches.unsqueeze(0).permute(0,2,1) + dc_in, input_img.shape[-2], input_img.shape[-1], patch_size)\n",
    "\n",
    "\n",
    "\n",
    "def build_image_mask(input_img, index_imgs, ref_imgs, mask_imgs, patch_size=7):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold(input_img)\n",
    "    for i, (ind_img, ref_img, mask_img) in enumerate(zip(index_imgs, ref_imgs, mask_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold(ind_img)\n",
    "            ref_patches = unfold(ref_img)\n",
    "            mask_patches = unfold(mask_img)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold(ind_img)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold(ref_img)], dim=-1)\n",
    "            mask_patches = torch.cat([mask_patches, unfold(mask_img)], dim=-1)\n",
    "    mask_patches = (mask_patches.mean(1).squeeze(0) == 1).byte()\n",
    "    print(mask_patches.shape, ref_patches.shape)\n",
    "    index_patches = index_patches[:,:,mask_patches]\n",
    "    ref_patches = ref_patches[:,:,mask_patches]\n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#                 print(start_patch, end_patch, dist_mat.shape)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0))\n",
    "    return patch2im(out_patches.unsqueeze(0).permute(0,2,1), input_img.shape[-2], input_img.shape[-1], patch_size)\n",
    "\n",
    "\n",
    "from fold import unfold2d, fold2d, view_as_column, view_as_image\n",
    "def build_image_bidirectional_weighted(input_img, index_imgs, ref_imgs, patch_size=7, eps=1):\n",
    "    unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "    in_patches = unfold2d(input_img, use_padding=False, use_view=True)\n",
    "    in_patches, patches_shape = view_as_column(in_patches)\n",
    "    for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "        if i == 0:\n",
    "            index_patches = unfold2d(ind_img, use_padding=False)\n",
    "            ref_patches = unfold2d(ref_img, use_padding=False)\n",
    "        else:\n",
    "            index_patches = torch.cat([index_patches, unfold2d(ind_img, use_padding=False)],dim=-1)\n",
    "            ref_patches = torch.cat([ref_patches, unfold2d(ref_img, use_padding=False)], dim=-1)\n",
    "            \n",
    "    if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "        for j in range(DIV):\n",
    "            start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "            end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "            dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "            dist_mat /= patch_size*patch_size*3\n",
    "            if start_patch < end_patch:\n",
    "                dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "            if j == 0:\n",
    "                ind = dist_mat.argmin(1)\n",
    "            elif start_patch < end_patch:\n",
    "                ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "    else:\n",
    "        dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "        dist_mat /= patch_size*patch_size*3\n",
    "        dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "        ind = dist_mat.argmin(1)\n",
    "    out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0)).unsqueeze(0).transpose(1,2)\n",
    "    out_patches = view_as_image(out_patches, patches_shape)\n",
    "    return fold2d(out_patches, reduce='weighted_mean', use_padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('leaky_relu'))\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers=8, chan=64, kernel_size=3, in_ch=3, out_ch=3, bias=True, padding_mode='reflect'):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        first_layer = [nn.Conv2d(in_channels=in_ch, out_channels=chan, kernel_size=kernel_size, bias=bias, padding = kernel_size//2, padding_mode=padding_mode),\n",
    "                            nn.ReLU(True)]\n",
    "        self.first_layer = nn.Sequential(*first_layer)\n",
    "        feature_block = []\n",
    "        for _ in range(1, n_layers - 1):\n",
    "            feature_block += [nn.Conv2d(in_channels=chan, out_channels=chan, kernel_size=kernel_size, bias=bias, padding = kernel_size//2, padding_mode=padding_mode),\n",
    "                              nn.ReLU(True)]\n",
    "        self.feature_block = nn.Sequential(*feature_block)\n",
    "        self.final_layer = nn.Sequential(nn.Conv2d(in_channels=chan, out_channels=out_ch, kernel_size=kernel_size, bias=bias, padding = kernel_size//2, padding_mode=padding_mode))\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        receptive_extraction = self.first_layer(input_tensor)\n",
    "        features = self.feature_block(receptive_extraction)\n",
    "        return self.final_layer(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generation\n",
    "\n",
    "def new_image_generation(src_pyr, dst_pyr, patch_size=7, top_level=9):\n",
    "    start = time.time()\n",
    "    new_im = dst_pyr[top_level] + torch.randn_like(dst_pyr[top_level])*0.75#new_pyr[9].clone()#\n",
    "    for l in range(top_level,-1,-1): \n",
    "        num_iters = 1 if l == top_level else 10\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "            if l == top_level:\n",
    "                new_im = build_image(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=7)\n",
    "            else:\n",
    "                new_im = build_image(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=7)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "    imshow(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def harmonization(src_pyr, dst_pyr, patch_size=7, top_level=1):\n",
    "    start = time.time()\n",
    "    new_im = dst_pyr[top_level] #new_pyr[9].clone()#\n",
    "    for l in range(top_level,-1,-1): \n",
    "        num_iters = 1\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "            if l == top_level:\n",
    "                new_im = build_image(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=patch_size)\n",
    "            else:\n",
    "                new_im = build_image(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=patch_size)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "    imshow(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    return new_im\n",
    "\n",
    "def edit(src_pyr, dst_pyr, mask_size, patch_size=7, top_level_max=9):\n",
    "    start = time.time()\n",
    "    top_level = int(np.floor(np.log(patch_size/mask_size)/np.log(3/4)))\n",
    "    top_level = min(top_level_max, top_level)\n",
    "    new_im = dst_pyr[top_level]\n",
    "    for l in range(top_level,-1,-1): \n",
    "        num_iters = 1 if l == top_level else 10\n",
    "        new_im = new_im + torch.randn_like(new_im)*(0.4**(10 -l))\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "            if l == top_level:\n",
    "                new_im = build_image(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=7)\n",
    "            else:\n",
    "                new_im = build_image(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=7)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "    imshow(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def summarization(pyr, ratio=(1/3,1/3), print_=False, patch_size=7, min_size=28, weighted_mean=False):\n",
    "    start = time.time()\n",
    "    new_im = pyr[0].clone()\n",
    "    imshow(new_im)\n",
    "    \n",
    "    \n",
    "    if ratio[0] <= 1 and ratio[1] <= 1:\n",
    "        num_steps = math.floor(max(math.log(ratio[0])/math.log(0.9), math.log(ratio[1])/math.log(0.9)))\n",
    "        step_size = [0.9, 0.9]\n",
    "        if ratio[0] > ratio[1]:\n",
    "            step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "        elif ratio[1] > ratio[0]:\n",
    "            step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "\n",
    "    elif ratio[0] >= 1 and ratio[1] >= 1:\n",
    "        num_steps = math.floor(max(math.log(ratio[0])/math.log(1.2), math.log(ratio[1])/math.log(1.2)))\n",
    "        step_size = [1.2, 1.2]\n",
    "        if ratio[0] < ratio[1]:\n",
    "            step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "        elif ratio[1] < ratio[0]:\n",
    "            step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "    \n",
    "    print(step_size, num_steps)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        rsizer = Resizer.Resizer(new_im.shape, step_size).cuda()\n",
    "        new_im = rsizer(new_im)\n",
    "        new_pyr = get_pyramids_aux(new_im, 15, 0.8, False)\n",
    "\n",
    "        top_level = math.floor(min(math.log(min_size/new_im.shape[-2])/math.log(0.8), math.log(min_size/new_im.shape[-1])/math.log(0.8)))\n",
    "        \n",
    "        print(top_level, new_pyr[top_level].shape)\n",
    "        \n",
    "        new_im = new_pyr[top_level].clone()#\n",
    "        start = time.time()\n",
    "        eps = (5e-3)\n",
    "        for l in range(top_level,-1,-1): \n",
    "            num_iters = 10\n",
    "            for k in range(num_iters):\n",
    "                rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "                if weighted_mean:\n",
    "                    new_im = build_image_bidirectional_weighted(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7, eps=eps)\n",
    "                else:\n",
    "                    new_im = build_image_bidirectional(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7, eps=eps)\n",
    "            imshow(new_im)\n",
    "            if l > 0:\n",
    "                rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "                new_im = rsizer(new_im)\n",
    "        print('Scale ' + str(i) + ', Total time: %.2f[s]' % (time.time() - start,))\n",
    "        imshow(new_im)\n",
    "\n",
    "        \n",
    "def Montage(pyrs, num_steps=10, print_=False, patch_size=7, min_size=28):\n",
    "    start = time.time()\n",
    "    for i, pyr in enumerate(pyrs):\n",
    "        if i == 0:\n",
    "            new_im = pyr[0]\n",
    "        else:\n",
    "            new_im = torch.cat([new_im, pyr[0]], dim=-1)\n",
    "    imshow(new_im)\n",
    "    \n",
    "    step_size = [1, 0.9]\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        rsizer = Resizer.Resizer(new_im.shape, step_size).cuda()\n",
    "        new_im = rsizer(new_im)\n",
    "        new_pyr = get_pyramids_aux(new_im, 15, 0.8, False)\n",
    "\n",
    "        top_level = math.floor(min(math.log(min_size/new_im.shape[-2])/math.log(0.8), math.log(min_size/new_im.shape[-1])/math.log(0.8)))\n",
    "        \n",
    "        print(top_level, new_pyr[top_level].shape)\n",
    "        \n",
    "        new_im = new_pyr[top_level].clone()#\n",
    "        start = time.time()\n",
    "        eps = (5e-4)\n",
    "        for l in range(top_level,-1,-1): \n",
    "            num_iters = 10\n",
    "            for k in range(num_iters):\n",
    "                keys = []\n",
    "                values = []\n",
    "                for pyr in pyrs:\n",
    "                    rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "                    keys.append(rsizer(pyr[l+1]))\n",
    "                    keys.append(pyr[l])\n",
    "                    values.append(pyr[l])\n",
    "                    values.append(pyr[l])\n",
    "                new_im = build_image_bidirectional(new_im, keys ,values, patch_size=7, eps=eps)\n",
    "            if l > 0:\n",
    "                rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "                new_im = rsizer(new_im)\n",
    "        print('Shape: ' + str(new_im.shape) + ', Scale: ' + str(i) + ', Total time: %.2f[s]' % (time.time() - start,))\n",
    "        imshow(new_im)\n",
    "\n",
    "        \n",
    "def structural_analogy(path_a, path_b, patch_size=7, top_layer=8, eps=5e-3, print_=False):\n",
    "    start = time.time()\n",
    "    pyr = get_pyramid(path_a,  None, 0, 20, 0.8, print_=print_) # Summary\n",
    "    pyr2 = get_pyramid(path_b, None, 0, 20, 0.8, print_=print_) # Summary\n",
    "    new_im = pyr2[0].clone()\n",
    "    for i in range(2):\n",
    "        new_pyr = get_pyramids_aux(new_im, 15, 0.8, print_)\n",
    "        new_im = new_pyr[top_layer].clone()\n",
    "        for l in range(top_layer,-1,-1): \n",
    "            num_iters = 10\n",
    "            for k in range(num_iters):\n",
    "                rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "                new_im = build_image_bidirectional(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7, eps=eps)\n",
    "            if l > 0:\n",
    "                rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "                new_im = rsizer(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    imshow(new_im)\n",
    "    imshow(pyr2[0])\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def structural_analogy_refinement(path_a, im, patch_size=7, top_layer=5, eps=5e-3, print_=False):\n",
    "    start = time.time()\n",
    "    pyr = get_pyramid(path_a,  None, 0, 20, 0.8, print_=print_)\n",
    "    new_pyr = get_pyramids_aux(im, 15, 0.8, print_)\n",
    "    new_im = new_pyr[top_layer].clone()\n",
    "    for l in range(top_layer,-1,-1): \n",
    "        num_iters = 10\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "            new_im = build_image(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    imshow(new_im)\n",
    "    imshow(pyr[0])\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def conditional_inpainting(im, mask, patch_size=7, top_layer=8, print_=False):\n",
    "    start = time.time()\n",
    "    pyr = get_pyramids_aux(im, 15, 0.75, print_=print_) # Summary\n",
    "    mask_pyr = get_pyramids_aux(mask, 15, 0.75, print_=print_) # Summary\n",
    "    new_im = pyr[top_layer]\n",
    "    for l in range(top_layer,-1,-1): \n",
    "        num_iters = 10\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(pyr[l+1].shape, 4/3, pyr[l].shape).cuda()\n",
    "            new_im = build_image_mask(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], [rsizer(mask_pyr[l+1]), mask_pyr[l]], patch_size=7)\n",
    "        imshow(new_im)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(pyr[l].shape, 4/3, pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    imshow(new_im)\n",
    "    imshow(pyr[0])\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birds, mountains Comparison\n",
    "pyr = get_pyramid('/home/nivg/data/mountains.jpg', None, 0, 15, 0.75, print_=True) \n",
    "pyr=pyr[3:]\n",
    "for ratio in ([[1,1],[1,4/5],[1,3/4],[1,1/3],[1,5/4],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mountains3 Comparison\n",
    "for ratio in ([[1,1],[1,1/3],[1,5/4],[4/5,1],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "        imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balloons Comparison\n",
    "for ratio in ([[1,1],[1,1/3],[1,5/4],[5/4,1],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "        imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Balloons/Colusseum for figure\n",
    "pyr = get_pyramid('/home/nivg/data/birds.png', None, 0, 15, 0.75, print_=True) \n",
    "\n",
    "for ratio in ([[1,1]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(10):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colusseum Comparison\n",
    "pyr = get_pyramid('/home/nivg/data/colusseum.png', None, 0, 15, 0.75, print_=True) \n",
    "# pyr=pyr[3:]\n",
    "imshow(pyr[0])\n",
    "for ratio in ([[1,1],[1,4/3],[4/3,1]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        if ratio == [4/3,1]:\n",
    "            im = new_image_generation(pyr, dst_pyr, top_level=8)\n",
    "        else:\n",
    "            im = new_image_generation(pyr, dst_pyr)\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seascape Harmonization\n",
    "IM_PATH = '/home/nivg/data/seascape.png'\n",
    "HARM_IM_PATH = '/home/nivg/data/seascape_naive.jpg'\n",
    "IM_NAME = 'seascape'\n",
    "pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True) \n",
    "pyr_harm = get_pyramid(HARM_IM_PATH, None, 0, 15, 0.75, print_=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starry night Harmonization\n",
    "IM_PATH = '/home/nivg/data/starry_night.png'\n",
    "HARM_IM_PATH = '/home/nivg/data/starry_night_naive.png'\n",
    "IM_NAME = 'starry_night'\n",
    "pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True) \n",
    "pyr_harm = get_pyramid(HARM_IM_PATH, None, 0, 15, 0.75, print_=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = harmonization(pyr, pyr_harm, top_level=0, patch_size=7)\n",
    "# imwrite('/home/nivg/data/DropGAN/image_harmonization/' + IM_NAME + '_harmonized.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Edit\n",
    "IM_PATH = '/home/nivg/data/stone.png'\n",
    "EDIT_IM_PATH = '/home/nivg/data/stone_edit.png'\n",
    "IM_NAME = 'stone'\n",
    "pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True)\n",
    "pyr_edit = get_pyramid(EDIT_IM_PATH, None, 0, 15, 0.75, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     im = edit(pyr, pyr_edit, mask_size=44, patch_size=7, top_level_max=9)\n",
    "#     imwrite('/home/nivg/data/DropGAN/image_editing/' + IM_NAME + '_edited_ver' + str(i) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stone Edit\n",
    "IM_PATH = '/home/nivg/data/stone.png'\n",
    "EDIT_IM_PATH = '/home/nivg/data/stone_edit.png'\n",
    "IM_NAME = 'stone'\n",
    "pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True) \n",
    "pyr_edit = get_pyramid(EDIT_IM_PATH, None, 0, 15, 0.75, print_=True) \n",
    "\n",
    "im = edit(pyr, pyr_edit, mask_size=44, patch_size=7, top_level_max=9)\n",
    "# imwrite('/home/nivg/data/DropGAN/image_editing/' + IM_NAME + '_edited.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Structural analogy\n",
    "# for im_a, im_b in [['205.jpg', '204.jpg'], ['204.jpg', '205.jpg'], ['208_resized.jpg', '209.jpg'], ['209.jpg', '208_resized.jpg'], \n",
    "#                    ['203.png', '202.png'], ['202.png', '203.png'], ['206.jpg', '207.jpg'], ['207.jpg', '206.jpg']]:\n",
    "\n",
    "#     IM_PATH_A = '/home/nivg/data/' + im_a\n",
    "#     IM_PATH_B = '/home/nivg/data/' + im_b\n",
    "# #     im, pyr_a = structural_analogy(IM_PATH_A, IM_PATH_B, print_=True, top_layer=8)\n",
    "# #     im1 = structural_analogy_refinement(im, pyr_a, patch_size=7)\n",
    "#     im = \n",
    "#     imshow(im)\n",
    "#     imshow(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_PATH_A = '/home/nivg/data/207.jpg'\n",
    "IM_PATH_B = '/home/nivg/data/206.jpg'\n",
    "im = structural_analogy(IM_PATH_A, IM_PATH_B, patch_size=7, top_layer=8, eps=5e-2, print_=False)\n",
    "structural_analogy_refinement(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_IM_PATH = '/home/nivg/data/farm_house_s.png'\n",
    "pyr = get_pyramid(SUMMARY_IM_PATH, None, 0, 22, 0.8, print_=False) \n",
    "pyr = pyr[2:]\n",
    "print(pyr[0].shape)\n",
    "im = summarization(pyr, ratio=(2,1), print_=True, min_size=35, weighted_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr1 = get_pyramid('/home/nivg/data/Tapestry_input_1.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/Tapestry_input_2.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr3 = get_pyramid('/home/nivg/data/Tapestry_input_3_resized.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "\n",
    "Montage([pyr1, pyr2, pyr3], num_steps=9, print_=False, patch_size=7, min_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Inpainting\n",
    "pyr = get_pyramid('/home/nivg/data/204.jpg', None, 0, 15,0.75)\n",
    "mask = torch.ones_like(pyr[0])\n",
    "mask[:,:,50:75, 20:40] = 0\n",
    "new_im = pyr[0].clone()\n",
    "for i in range(3):\n",
    "    if i == 2:\n",
    "        new_im[:,i,50:75, 20:40] = 0\n",
    "    else:\n",
    "        new_im[:,i,50:75, 20:40] = 1\n",
    "conditional_inpainting(new_im, mask, patch_size=7, top_layer=5, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/BSDS100/296007.png', None, 0, 15,0.75)\n",
    "pyr = pyr[2:]\n",
    "mask = torch.ones_like(pyr[0])\n",
    "mask[:,:,130:165, 160:190] = 0\n",
    "new_im = pyr[0].clone()#*mask\n",
    "imshow(new_im)\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        new_im[:,:,140:165, 160:190] = 0.0\n",
    "    else:\n",
    "        for j in range(3):\n",
    "            if j < 2:\n",
    "                new_im[:,j,140:165, 160:190] = 0.7\n",
    "            else:\n",
    "                new_im[:,j,140:165, 160:190] = 0.3\n",
    "    conditional_inpainting(new_im, mask, patch_size=7, top_layer=4, print_=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
