{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mn100.mcl.weizmann.ac.il\u001b[m  Fri Jan 28 11:29:32 2022  \u001b[1m\u001b[30m455.32.00\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla V100-PCIE-16GB\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m16160\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTesla V100-PCIE-16GB\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m16160\u001b[m MB |\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTesla V100-PCIE-16GB\u001b[m |\u001b[1m\u001b[31m 61'C\u001b[m, \u001b[1m\u001b[32m 99 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m16127\u001b[m / \u001b[33m16160\u001b[m MB | \u001b[1m\u001b[30modeliam\u001b[m:\u001b[36mpython\u001b[m(\u001b[33m16123M\u001b[m)\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTesla V100-PCIE-16GB\u001b[m |\u001b[1m\u001b[31m 60'C\u001b[m, \u001b[1m\u001b[32m 97 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m16145\u001b[m / \u001b[33m16160\u001b[m MB | \u001b[1m\u001b[30modeliam\u001b[m:\u001b[36mpython\u001b[m(\u001b[33m16141M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat -cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from bm3d import bm3d\n",
    "from image import imread, imwrite, imshow, to_numpy\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2pt(arr):\n",
    "    return torch.tensor(arr).permute(2, 0, 1).unsqueeze(0).contiguous()\n",
    "\n",
    "def pt2np(tensor):\n",
    "    return to_numpy(tensor.squeeze(0).permute(1, 2, 0))\n",
    "\n",
    "def bm3d_denoise(input, sigma):\n",
    "    return np2pt(bm3d(pt2np(input), sigma)).to(device=input.device, dtype=input.dtype)\n",
    "\n",
    "def imread2pt(path, d=None, **kwargs):\n",
    "    image = imread(path, **kwargs)\n",
    "    image = np2pt(image)\n",
    "    # image = torch.tensor(imread(path, **kwargs)).permute(2, 0, 1).unsqueeze(0)\n",
    "    if d is not None:\n",
    "        image = shave_image(image, d)\n",
    "    return image.contiguous()\n",
    "\n",
    "def get_psnr(a, b, bounds=(0., 1.)):\n",
    "    mse = F.mse_loss(a, b)\n",
    "    return 20 * math.log10(bounds[1] - bounds[0]) - 10 * mse.log10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Resizer\n",
    "from PIL import Image\n",
    "def get_pyramids_aux(img_torch, num_layers,ratio, print_):\n",
    "    max_layer = num_layers\n",
    "    pyr = []\n",
    "    ratio = ratio\n",
    "    if isinstance(ratio, float) or isinstance(ratio, int):\n",
    "        ratio = (ratio, ratio)\n",
    "    curr_img = img_torch\n",
    "    pyr.append(curr_img)\n",
    "    for j in range(max_layer):\n",
    "        if print_:\n",
    "            print(curr_img.shape)\n",
    "            imshow(curr_img)\n",
    "        rsizer = Resizer.Resizer(curr_img.shape, ratio, [1,img_torch.shape[1], np.ceil(img_torch.shape[2]*(ratio[0])**(j+1)), np.ceil(img_torch.shape[3]*(ratio[1])**(j+1))]).cuda()\n",
    "        curr_img = rsizer(curr_img)\n",
    "        pyr.append(curr_img)\n",
    "        \n",
    "    return pyr\n",
    "\n",
    "def get_pyramid(file, degradation, sigma, num_layers, ratio, print_=True):\n",
    "\n",
    "    gt = np.expand_dims(imread(file),0)\n",
    "    gt = torch.tensor(gt).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "            \n",
    "    return get_pyramids_aux(gt, num_layers,ratio, print_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.arange(30).reshape(2, 5, 3)\n",
    "m = torch.ones((2, 5, 3), dtype=torch.bool)\n",
    "m[0, 0, 1] = False\n",
    "m[0, 0, 1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIV = 100\n",
    "\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "import fold\n",
    "import new_utils as utils\n",
    "\n",
    "from fold import unfold2d, fold2d, view_as_column, view_as_image\n",
    "\n",
    "def _unfold2d_to_column(image, *args, **kwargs):\n",
    "    unfolded = fold.unfold2d(image, *args, **kwargs)\n",
    "    return fold.view_as_column(fold.unfold2d(image))[0]\n",
    "\n",
    "def pnn(queries: torch.Tensor, keys: torch.Tensor, values: torch.Tensor, \n",
    "        masks: Optional[torch.Tensor] = None, patch_size: int = 7, alpha: float = 10.0, \n",
    "        reduce='weighted_mean'):\n",
    "    query_patches = fold.unfold2d(queries)\n",
    "    query_patches_column, query_patches_size = fold.view_as_column(query_patches)        \n",
    "    key_patches_column, _ = fold.view_as_column(fold.unfold2d(keys))\n",
    "    value_patches_column, _= fold.view_as_column(fold.unfold2d(values))\n",
    "    if masks is not None:\n",
    "        mask_patches_column, _ = fold.view_as_column(fold.unfold2d(masks))\n",
    "        unmasked_patches = mask_patches_column.sum(dim=2) > mask_patches_column.shape[2] - 0.5\n",
    "        key_patches_column = key_patches_column[:, :, unmasked_patches]\n",
    "        value_patches_column = value_patches_column[:, :, unmasked_patches]\n",
    "    dist = utils.compute_dist_matrix(query_patches_column, key_patches_column)  # MSE\n",
    "    dist /= dist.min(dim=0, keepdim=True)[0] + alpha\n",
    "    indices = dist.argmin(1)\n",
    "    out_patches_column = F.embedding(indices, value_patches_column)  # .unsqueeze(0).transpose(1,2)\n",
    "    out_patches = view_as_image(out_patches_column, query_patches_size)\n",
    "    return fold2d(out_patches, reduce=reduce)\n",
    "\n",
    "# def build_image_bidirectional_weighted(input_img, index_imgs, ref_imgs, patch_size=7, eps=1):\n",
    "#     unfold = torch.nn.Unfold(kernel_size=(patch_size,patch_size))\n",
    "#     in_patches = unfold2d(input_img, use_padding=False, use_view=True)\n",
    "#     in_patches, patches_shape = view_as_column(in_patches)\n",
    "#     for i, (ind_img, ref_img) in enumerate(zip(index_imgs, ref_imgs)):\n",
    "#         if i == 0:\n",
    "#             index_patches = unfold2d(ind_img, use_padding=False)\n",
    "#             ref_patches = unfold2d(ref_img, use_padding=False)\n",
    "#         else:\n",
    "#             index_patches = torch.cat([index_patches, unfold2d(ind_img, use_padding=False)],dim=-1)\n",
    "#             ref_patches = torch.cat([ref_patches, unfold2d(ref_img, use_padding=False)], dim=-1)\n",
    "            \n",
    "#     if in_patches.shape[-1]*ref_patches.shape[-1] > 14000**2:\n",
    "#         for j in range(DIV):\n",
    "#             start_patch = j*(math.ceil(in_patches.shape[-1]/DIV))\n",
    "#             end_patch = min((j+1)*(math.ceil(in_patches.shape[-1]/DIV)), in_patches.shape[-1])\n",
    "#             dist_mat = _calc_dist_l2(in_patches[:,:,start_patch:end_patch].permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#             dist_mat /= patch_size*patch_size*3\n",
    "#             if start_patch < end_patch:\n",
    "#                 dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "#             if j == 0:\n",
    "#                 ind = dist_mat.argmin(1)\n",
    "#             elif start_patch < end_patch:\n",
    "#                 ind = torch.cat([ind, dist_mat.argmin(1)])\n",
    "\n",
    "#     else:\n",
    "#         dist_mat = _calc_dist_l2(in_patches.permute(0,2,1).squeeze(0), index_patches.squeeze(0).permute(1,0))\n",
    "#         dist_mat /= patch_size*patch_size*3\n",
    "#         dist_mat = dist_mat/(dist_mat.min(0, keepdim=True)[0] + eps)\n",
    "#         ind = dist_mat.argmin(1)\n",
    "#     out_patches = F.embedding(ind, ref_patches.squeeze(0).permute(1,0)).unsqueeze(0).transpose(1,2)\n",
    "#     out_patches = view_as_image(out_patches, patches_shape)\n",
    "#     return fold2d(out_patches, reduce='weighted_mean', use_padding=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean functions\n",
    "import resize_right\n",
    "\n",
    "def gpnn(pyr: list, query: torch.Tensor, noise_std: float = 0.75, alpha: float = 10.0,\n",
    "        downscale_ratio: float = 0.75, patch_size: int = 7, reduce: str = 'weighted_mean'):\n",
    "  start = time.time()\n",
    "  query += torch.randn_like(query)*noise_std\n",
    "  for l in range(len(pyr),-1,-1): \n",
    "    num_iters = 1 if l == top_level else 10\n",
    "    for k in range(num_iters):\n",
    "        if l == top_level:\n",
    "            new_im = pnn(query, key=[pyr[l]] ,value=[pyr[l]], patch_size=patch_size, reduce=reduce)\n",
    "        else:\n",
    "            blurred = resize_right.resize(pyr[l+1], 1/downscale_ratio, pyr[l].shape)\n",
    "            # rsizer = Resizer.Resizer(pyr[l+1].shape, 1/downscale_ratio, pyr[l].shape).to(device=device)\n",
    "            query = pnn(query, key=[blurred] ,value=[pyr[l]], patch_size=patch_size, reduce=reduce)\n",
    "    if l > 0:\n",
    "        query = resize_right.resize(pyr[l], 1/downscale_ratio, pyr[l-1].shape)\n",
    "        # rsizer = Resizer.Resizer(pyr[l].shape, 1/downscale_ratio, pyr[l-1].shape).to(device=device)\n",
    "  print('Total time: %.3f[s]' % (time.time() - start,))\n",
    "  return query\n",
    "\n",
    "def image_generation(input_path: str, noise_std: float = 0.75, alpha: float = 10.0,\n",
    "                    patch_size: int = 7, reduce: str = 'weighted_mean', \n",
    "                    downscale_ratio: float = 0.75, num_levels: int = 9):\n",
    "    pyr = make_pyramid(imread(input_path), num_levels, downscale_ratio)\n",
    "    return gpnn(pyr, query=pyr[-1], noise_std=noise_std, alpha=alpha, \n",
    "        downscale_ratio=downscale_ratio, patch_size=patch_size, reduce=reduce)\n",
    "\n",
    "def image_editing(input_path: str, input_path_edited: str, noise_std: float = 0.75, \n",
    "                    alpha: float = 10.0, device: str = 'cuda', \n",
    "                    patch_size: int = 7, reduce: str = 'weighted_mean', \n",
    "                    downscale_ratio: float = 0.75, num_levels: int = 9):\n",
    "    pyr = make_pyramid(imread(input_path), num_levels, downscale_ratio)\n",
    "    pyr_edited = make_pyramid(imread(input_path_edited), num_levels, downscale_ratio)\n",
    "    return gpnn(pyr, query=pyr_edited[-1], noise_std=noise_std, alpha=alpha, \n",
    "        downscale_ratio=downscale_ratio, device=device, patch_size=patch_size,\n",
    "        reduce=reduce)\n",
    "\n",
    "def retargeting(input_path: str, noise_std: float = 0.0, \n",
    "                alpha: float = 1e-3, device: str = 'cuda', \n",
    "                patch_size: int = 7, reduce: str = 'weighted_mean', \n",
    "                downscale_ratio: float = 0.8, num_levels: int = 9,\n",
    "                retargeting_ratio: tuple = (0.75, 0.75), gradual: bool = False):\n",
    "    pyr = make_pyramid(imread(input_path), num_levels, downscale_ratio)\n",
    "    if gradual:\n",
    "        step_size = [0.9, 0.9]\n",
    "        if retargeting_ratio[0] >= 1:\n",
    "            step_size[0] = 1.1\n",
    "        if retargeting_ratio[1] >= 1:\n",
    "            step_size[0] = 1.1\n",
    "        num_steps = math.floor(max(math.log(ratio[0])/math.log(step_size[0]), \n",
    "                                math.log(ratio[1])/math.log(step_size[1])))\n",
    "        step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "        step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "\n",
    "\n",
    "\n",
    "    resized = resize_right.resize(pyr[0], retargeting_ratio)\n",
    "    top_level = math.floor(min(math.log(min_size/new_im.shape[-2])/math.log(downscale_ratio), \n",
    "                math.log(min_size/new_im.shape[-1])/math.log(downscale_ratio)))\n",
    "    retargeted_pyr = make_pyramid(resized, top_level, downscale_ratio)        \n",
    "    query = new_pyr[top_level].clone()\n",
    "    return gpnn(pyr, query=query, noise_std=noise_std, alpha=alpha, \n",
    "        downscale_ratio=downscale_ratio, device=device, patch_size=patch_size,\n",
    "        reduce=reduce)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generation\n",
    "\n",
    "\n",
    "# def new_image_generation(src_pyr, dst_pyr, patch_size=7, top_level=9, noise_std=0.75):\n",
    "#     start = time.time()\n",
    "#     new_im = dst_pyr[top_level] + torch.randn_like(dst_pyr[top_level])*noise_std\n",
    "#     print(new_im.shape)\n",
    "#     for l in range(top_level,-1,-1): \n",
    "#         num_iters = 1 if l == top_level else 10\n",
    "#         for k in range(num_iters):\n",
    "#             rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "#             if l == top_level:\n",
    "#                 new_im = build_image_weighted(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=7)\n",
    "#             else:\n",
    "#                 new_im = build_image_weighted(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=7)\n",
    "# #         imshow(torch.cat([new_im,pyr[l]], dim=-1))\n",
    "#         if l > 0:\n",
    "#             rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "#             new_im = rsizer(new_im)\n",
    "# #     imshow(new_im)\n",
    "#     print('Total time: %.3f[s]' % (time.time() - start,))\n",
    "#     return new_im\n",
    "\n",
    "\n",
    "# def edit(src_pyr, dst_pyr, mask_size, patch_size=7, top_level_max=9):\n",
    "#     start = time.time()\n",
    "#     top_level = int(np.floor(np.log(patch_size/mask_size)/np.log(3/4)))\n",
    "#     top_level = min(top_level_max, top_level)\n",
    "#     new_im = dst_pyr[top_level]\n",
    "#     for l in range(top_level,-1,-1): \n",
    "#         num_iters = 1 if l == top_level else 10\n",
    "#         new_im = new_im + torch.randn_like(new_im)*(0.4**(10 -l))\n",
    "#         for k in range(num_iters):\n",
    "#             rsizer = Resizer.Resizer(src_pyr[l+1].shape, 4/3, src_pyr[l].shape).cuda()\n",
    "#             if l == top_level:\n",
    "#                 new_im = build_image(new_im, [src_pyr[l]] ,[src_pyr[l]], patch_size=7)\n",
    "#             else:\n",
    "#                 new_im = build_image(new_im, [rsizer(src_pyr[l+1])] ,[src_pyr[l]], patch_size=7)\n",
    "#         if l > 0:\n",
    "#             rsizer = Resizer.Resizer(dst_pyr[l].shape, 4/3, dst_pyr[l-1].shape).cuda()\n",
    "#             new_im = rsizer(new_im)\n",
    "#     imshow(new_im)\n",
    "#     print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "#     return new_im\n",
    "\n",
    "\n",
    "# def summarization(pyr, ratio=(1/3,1/3), print_=False, patch_size=7, min_size=28, weighted_mean=False, gradual=True, eps=5e-3):\n",
    "#     start = time.time()\n",
    "#     new_im = pyr[0].clone()\n",
    "#     imshow(new_im)\n",
    "    \n",
    "#     if gradual:\n",
    "#         if ratio[0] <= 1 and ratio[1] <= 1:\n",
    "#             num_steps = math.floor(max(math.log(ratio[0])/math.log(0.9), math.log(ratio[1])/math.log(0.9)))\n",
    "#             step_size = [0.9, 0.9]\n",
    "#             if ratio[0] > ratio[1]:\n",
    "#                 step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "#             elif ratio[1] > ratio[0]:\n",
    "#                 step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "\n",
    "#         elif ratio[0] >= 1 and ratio[1] >= 1:\n",
    "#             num_steps = math.floor(max(math.log(ratio[0])/math.log(1.2), math.log(ratio[1])/math.log(1.2)))\n",
    "#             step_size = [1.2, 1.2]\n",
    "#             if ratio[0] < ratio[1]:\n",
    "#                 step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "#             elif ratio[1] < ratio[0]:\n",
    "#                 step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "                \n",
    "#         elif ratio[0] < 1 and ratio[1] >= 1:\n",
    "#             num_steps = math.floor(max(math.log(ratio[0])/math.log(0.9), math.log(ratio[1])/math.log(1.2)))\n",
    "#             step_size = [1.2, 1.2]\n",
    "#             if ratio[0] < ratio[1]:\n",
    "#                 step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "#             elif ratio[1] < ratio[0]:\n",
    "#                 step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "        \n",
    "#         elif ratio[0] >= 1 and ratio[1] < 1:\n",
    "#             num_steps = math.floor(max(math.log(ratio[0])/math.log(1.2), math.log(ratio[1])/math.log(0.9)))\n",
    "#             step_size = [1.2, 1.2]\n",
    "#             step_size[0] = 10**(math.log10(ratio[0])/num_steps)\n",
    "#             step_size[1] = 10**(math.log10(ratio[1])/num_steps)\n",
    "\n",
    "#         print(step_size, num_steps)\n",
    "    \n",
    "#     else:\n",
    "#         step_size = [ratio[0],ratio[1]]\n",
    "#         num_steps=1\n",
    "    \n",
    "#     results = []\n",
    "#     for i in range(num_steps):\n",
    "#         rsizer = Resizer.Resizer(new_im.shape, step_size).cuda()\n",
    "#         new_im = rsizer(new_im)\n",
    "#         new_pyr = get_pyramids_aux(new_im, 16, 0.8, False)\n",
    "#         top_level = math.floor(min(math.log(min_size/new_im.shape[-2])/math.log(0.8), math.log(min_size/new_im.shape[-1])/math.log(0.8)))\n",
    "        \n",
    "#         print(top_level, new_pyr[top_level].shape, pyr[top_level].shape)\n",
    "        \n",
    "#         new_im = new_pyr[top_level].clone() #\n",
    "#         start = time.time()\n",
    "#         for l in range(top_level,-1,-1): \n",
    "#             print(l, new_pyr[l].shape, pyr[l].shape)\n",
    "#             num_iters = 10\n",
    "#             for k in range(num_iters):\n",
    "#                 rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "#                 if weighted_mean:\n",
    "#                     new_im = build_image_bidirectional_weighted(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7, eps=eps)\n",
    "#                 else:\n",
    "#                     new_im = build_image_bidirectional(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=7, eps=eps)\n",
    "#             imshow(new_im)\n",
    "#             if l > 0:\n",
    "#                 rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "#                 new_im = rsizer(new_im)\n",
    "#         print('Scale ' + str(i) + ', Total time: %.2f[s]' % (time.time() - start,))\n",
    "#         imshow(new_im)\n",
    "#         results.append(new_im)\n",
    "#     return new_im, results\n",
    "\n",
    "\n",
    "\n",
    "def Montage(pyrs, new_im, num_steps=10, print_=False, patch_size=7, min_size=28, eps=5e-3, noise_std=0.75):\n",
    "    start = time.time()\n",
    "#     for i, pyr in enumerate(pyrs):\n",
    "#         if i == 0:\n",
    "#             new_im = pyr[0]\n",
    "#         else:\n",
    "#             new_im = torch.cat([new_im, pyr[0]], dim=-1)\n",
    "#     imshow(new_im)\n",
    "    \n",
    "    step_size = [1, 0.9]\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        rsizer = Resizer.Resizer(new_im.shape, step_size).cuda()\n",
    "        new_im = rsizer(new_im)\n",
    "        new_pyr = get_pyramids_aux(new_im, 15, 0.8, False)\n",
    "\n",
    "        top_level = math.floor(min(math.log(min_size/new_im.shape[-2])/math.log(0.8), math.log(min_size/new_im.shape[-1])/math.log(0.8)))\n",
    "        \n",
    "        print(top_level, new_pyr[top_level].shape)\n",
    "        \n",
    "        new_im = new_pyr[top_level].clone() + new_pyr[top_level].clone()*noise_std\n",
    "        start = time.time()\n",
    "        for l in range(top_level,-1,-1):            \n",
    "            num_iters = 10\n",
    "            for k in range(num_iters):\n",
    "                keys = []\n",
    "                values = []\n",
    "                for pyr in pyrs:\n",
    "                    rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "                    keys.append(rsizer(pyr[l+1]))\n",
    "                    keys.append(pyr[l])\n",
    "                    values.append(pyr[l])\n",
    "                    values.append(pyr[l])\n",
    "                new_im = build_image_bidirectional(new_im, keys ,values, patch_size=7, eps=eps)\n",
    "            imshow(new_im)\n",
    "            if l > 0:\n",
    "                rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "                new_im = rsizer(new_im)\n",
    "        print('Shape: ' + str(new_im.shape) + ', Scale: ' + str(i) + ', Total time: %.2f[s]' % (time.time() - start,))\n",
    "        imshow(new_im)\n",
    "\n",
    "        \n",
    "def structural_analogy(path_a, path_b, patch_size=7, top_layer=8, eps=5e-3, print_=False):\n",
    "    start = time.time()\n",
    "    pyr = get_pyramid(path_a,  None, 0, 20, 0.8, print_=print_) # Summary\n",
    "    pyr2 = get_pyramid(path_b, None, 0, 20, 0.8, print_=print_) # Summary\n",
    "    new_im = pyr2[0].clone()\n",
    "    print(new_im.shape)\n",
    "    for i in range(1):\n",
    "        new_pyr = get_pyramids_aux(new_im, 20, 0.8, print_)\n",
    "        new_im = new_pyr[top_layer].clone()\n",
    "        for l in range(top_layer,-1,-1): \n",
    "            num_iters = 10\n",
    "            for k in range(num_iters):\n",
    "                rsizer = Resizer.Resizer(pyr[l+1].shape, 5/4, pyr[l].shape).cuda()\n",
    "                new_im = build_image_bidirectional(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], patch_size=patch_size, eps=eps)\n",
    "#             imshow(torch.cat([new_im, pyr2[l]], dim=-1))\n",
    "            if l > 0:\n",
    "                rsizer = Resizer.Resizer(new_pyr[l].shape, 5/4, new_pyr[l-1].shape).cuda()\n",
    "                new_im = rsizer(new_im)\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    imshow(torch.cat([new_im, pyr2[l]], dim=-1))\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def conditional_inpainting(im, mask, patch_size=7, top_layer=8, print_=False):\n",
    "    start = time.time()\n",
    "    pyr = get_pyramids_aux(im, 15, 0.75, print_=print_) # Summary\n",
    "    mask_pyr = get_pyramids_aux(mask, 15, 0.75, print_=print_) # Summary\n",
    "    new_im = pyr[top_layer]\n",
    "    for l in range(top_layer,-1,-1): \n",
    "        num_iters = 10\n",
    "        for k in range(num_iters):\n",
    "            rsizer = Resizer.Resizer(pyr[l+1].shape, 4/3, pyr[l].shape).cuda()\n",
    "            new_im = build_image_mask(new_im, [rsizer(pyr[l+1]), pyr[l]] ,[pyr[l], pyr[l]], [rsizer(mask_pyr[l+1]), mask_pyr[l]], patch_size=patch_size)\n",
    "        imshow(new_im)\n",
    "        if l > 0:\n",
    "            rsizer = Resizer.Resizer(pyr[l].shape, 4/3, pyr[l-1].shape).cuda()\n",
    "            new_im = rsizer(new_im)\n",
    "\n",
    "    print('Total time: %.2f[s]' % (time.time() - start,))\n",
    "    imshow(new_im)\n",
    "    imshow(pyr[0])\n",
    "    return new_im\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor([5])\n",
      "Total time: 5.03[s]\n",
      "Total time: 2.94[s]\n",
      "Total time: 2.84[s]\n",
      "Total time: 2.94[s]\n",
      "Total time: 2.91[s]\n",
      "Total time: 2.88[s]\n",
      "Total time: 2.90[s]\n",
      "Total time: 2.84[s]\n",
      "Total time: 2.92[s]\n",
      "Total time: 2.87[s]\n",
      "Total time: 2.79[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.78[s]\n",
      "Total time: 2.66[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.67[s]\n",
      "Total time: 2.72[s]\n",
      "Total time: 2.69[s]\n",
      "Total time: 2.82[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.72[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.78[s]\n",
      "Total time: 2.80[s]\n",
      "Total time: 2.71[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.85[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.80[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.84[s]\n",
      "Total time: 2.81[s]\n",
      "Total time: 2.69[s]\n",
      "Total time: 2.71[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.71[s]\n",
      "Total time: 2.94[s]\n",
      "Total time: 2.79[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.78[s]\n",
      "Total time: 2.86[s]\n",
      "Total time: 2.92[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.71[s]\n",
      "Total time: 2.81[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.82[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.73[s]\n",
      "Total time: 2.72[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.86[s]\n",
      "Total time: 2.94[s]\n",
      "Total time: 2.86[s]\n",
      "Total time: 2.88[s]\n",
      "Total time: 2.86[s]\n",
      "Total time: 2.85[s]\n",
      "Total time: 2.83[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.71[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.84[s]\n",
      "Total time: 2.78[s]\n",
      "Total time: 2.78[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.89[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.62[s]\n",
      "Total time: 2.69[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.68[s]\n",
      "Total time: 2.72[s]\n",
      "Total time: 2.83[s]\n",
      "Total time: 2.72[s]\n",
      "Total time: 2.76[s]\n",
      "Total time: 2.79[s]\n",
      "Total time: 2.75[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.74[s]\n",
      "Total time: 2.75[s]\n",
      "99\n",
      "0.42391304347826086\n",
      "Total time: 2.77[s]\n",
      "Total time: 2.88[s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-772ba50f9b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#     print(test_label==norm_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manomaly_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnorm_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-06e3045bf206>\u001b[0m in \u001b[0;36manomaly_detection\u001b[0;34m(norm_image, test_image, patch_size, top_level, print_)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mnorm_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nivg/data/norm_im_tmp.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                     \u001b[0mtest_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nivg/data/test_im_tmp.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0mpyr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pyramid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nivg/data/norm_im_tmp.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0mtest_pyr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pyramid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nivg/data/test_im_tmp.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-738eddb3875e>\u001b[0m in \u001b[0;36mget_pyramid\u001b[0;34m(file, degradation, sigma, num_layers, ratio, print_)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_pyramids_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-738eddb3875e>\u001b[0m in \u001b[0;36mget_pyramids_aux\u001b[0;34m(img_torch, num_layers, ratio, print_)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrsizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mcurr_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-image-prior/ProjNet/Resizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_shape, scale_factor, output_shape, kernel, antialiasing)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# for each coordinate (along 1 dim), calculate which coordinates in the input image affect its result and the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# weights that multiply the values there to get its result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_of_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialiasing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# convert to torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-image-prior/ProjNet/Resizer.py\u001b[0m in \u001b[0;36mcontributions\u001b[0;34m(self, in_length, out_length, scale, kernel, kernel_width, antialiasing)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# vertical dim is a list of weights matching to the pixel in the field of view (that are specified in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# 'field_of_view')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfield_of_view\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Normalize weights to sum up to 1. be careful from dividing by 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-image-prior/ProjNet/Resizer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# When anti-aliasing is activated (default and only for downscaling) the receptive field is stretched to size of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# 1/sf. this means filtering is more 'low-pass filter'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mfixed_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mantialiasing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mkernel_width\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mantialiasing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-image-prior/ProjNet/Resizer.py\u001b[0m in \u001b[0;36mcubic\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mabsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mabsx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mabsx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabsx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     return ((1.5*absx3 - 2.5*absx2 + 1) * (absx <= 1) +\n\u001b[1;32m    176\u001b[0m             (-0.5*absx3 + 2.5*absx2 - 4*absx + 2) * ((1 < absx) & (absx <= 2)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('/home/nivg/Projects/mturk-dg/exp1/sigd_dg/')\n",
    "\n",
    "for file in files:\n",
    "    pyr = get_pyramid('/home/nivg/Projects/mturk-dg/exp1/sigd_dg/' + file, None, 0, 1, 0.75, print_=False) \n",
    "    pyr_gt = get_pyramid('/home/nivg/Projects/mturk-dg/exp1/sigd_gt/' + file, None, 0, 1, 0.75, print_=False) \n",
    "    print(file, get_psnr(pyr[0],pyr_gt[0]))\n",
    "    imshow((pyr[0] - pyr_gt[0]).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birds, mountains Comparison\n",
    "pyr = get_pyramid('/home/nivg/data/mountains.jpg', None, 0, 15, 0.75, print_=True) \n",
    "pyr=pyr[3:]\n",
    "for ratio in ([[1,1],[1,4/5],[1,3/4],[1,1/3],[1,5/4],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Birds, mountains Comparison\n",
    "pyr = get_pyramid('/home/nivg/data/DropGAN/user_study/newDS_jpg/birds_3.jpg', None, 0, 15, 0.75, print_=True) \n",
    "for ratio in ([[1,1]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(10):\n",
    "        im = new_image_generation_adaptive(pyr, dst_pyr)\n",
    "        imshow(im)\n",
    "        print(get_psnr(pyr[0], im))\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(r[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Animation attempt\n",
    "images = []\n",
    "BASE_PATH = '/home/nivg/data/'\n",
    "files = os.listdir(BASE_PATH)\n",
    "for file in ['wild_bush.png']:#,'smiley.jpg','crazy-building.jpg','checkers.jpg']:#['cookies.jpg', 'ladakh_horses.jpg', 'vietnam_traffic.jpg', 'people_on_the_beach.jpg','smiley.jpg',]:\n",
    "    pyr = get_pyramid(BASE_PATH + file, None, 0, 15, 0.75, print_=False)\n",
    "    im = pyr[0].detach().clone()\n",
    "    for ratio in ([[1,1]]):\n",
    "        for k in range(30):\n",
    "#             pyr = get_pyramids_aux(im, num_layers=15, ratio=0.75, print_=False)\n",
    "            dst_pyr = get_pyramids_aux(im, num_layers=15, ratio=0.75, print_=False)\n",
    "            im = new_image_generation_adaptive(pyr, dst_pyr,top_level=2, noise_std=1.75)\n",
    "            imshow(im)\n",
    "            print(get_psnr(im, pyr[0]))\n",
    "            images.append(im.detach().clone().squeeze(0).permute(1,2,0).cpu())\n",
    "#             imwrite('/home/nivg/data/DropGAN/image_generation/' + file.split('.')[0] + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '_hr.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mountains3 Comparison\n",
    "for ratio in ([[1,1],[1,1/3],[1,5/4],[4/5,1],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "        imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balloons Comparison\n",
    "for ratio in ([[1,1],[1,1/3],[1,5/4],[5/4,1],[1,2]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "        imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Balloons/Colusseum/Birds for figure\n",
    "pyr = get_pyramid('/home/nivg/data/corn.png', None, 0, 15, 0.75, print_=True) \n",
    "pyr = pyr[1:]\n",
    "for ratio in ([[1,1]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(10):\n",
    "        im = new_image_generation(pyr, dst_pyr)\n",
    "        imshow(im)\n",
    "        print(get_psnr(im, pyr[0]))\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colusseum Comparison\n",
    "pyr = get_pyramid('/home/nivg/data/colusseum.png', None, 0, 15, 0.75, print_=True) \n",
    "# pyr=pyr[3:]\n",
    "imshow(pyr[0])\n",
    "for ratio in ([[1,1],[1,4/3],[4/3,1]]):\n",
    "    rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "    dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "    for k in range(2):\n",
    "        if ratio == [4/3,1]:\n",
    "            im = new_image_generation(pyr, dst_pyr, top_level=8)\n",
    "        else:\n",
    "            im = new_image_generation(pyr, dst_pyr)\n",
    "#         imwrite('/home/nivg/data/DropGAN/image_generation/' + IM_NAME + '_' + str(ratio[0]) + '_' + str(ratio[1]) +  '_im' + str(k) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = harmonization(pyr, pyr_harm, top_level=0, patch_size=7)\n",
    "# imwrite('/home/nivg/data/DropGAN/image_harmonization/' + IM_NAME + '_harmonized.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Edit\n",
    "IM_PATH = '/home/nivg/data/stone.png'\n",
    "EDIT_IM_PATH = '/home/nivg/data/stone_edit.png'\n",
    "IM_NAME = 'stone'\n",
    "pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True)\n",
    "pyr_edit = get_pyramid(EDIT_IM_PATH, None, 0, 15, 0.75, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     im = edit(pyr, pyr_edit, mask_size=44, patch_size=7, top_level_max=9)\n",
    "#     imwrite('/home/nivg/data/DropGAN/image_editing/' + IM_NAME + '_edited_ver' + str(i) + '.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stone Edit\n",
    "IM_PATH = '/home/nivg/data/DropGAN/user_study/newDS_jpg/baseball.jpg'\n",
    "EDIT_IM_PATH = '/home/nivg/data/DropGAN/image_editing/baseball_edited.jpg'\n",
    "IM_NAME = 'stone'\n",
    "# pyr = get_pyramid(IM_PATH, None, 0, 15, 0.75, print_=True) \n",
    "mask = torch.zeros_like(pyr_edit[0])\n",
    "mask[:,:,50:110, 190:245] = 1\n",
    "# mask[:,:,50:115, 140:180] = 1\n",
    "\n",
    "imshow(mask)\n",
    "# pyr_edit = get_pyramid(EDIT_IM_PATH, None, 0, 15, 0.75, print_=True)\n",
    "# im = edit(pyr, pyr_edit, mask_size=35, patch_size=7, top_level_max=9)\n",
    "# imwrite('/home/nivg/data/DropGAN/image_editing/' + IM_NAME + '_edited.png', im.squeeze(0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Structural Analogies \\ Paint to Image\n",
    "\n",
    "# 206, 207 - 10, 5e-3\n",
    "# 207, 206 - 8, 5e-2\n",
    "# 204, 205 - 4, 5e-1\n",
    "# 205, 204 - 4, 5e-3\n",
    "# 202, 203 - 4, 5e-4\n",
    "# 203, 202 - 2, 5e-4\n",
    "# 208_resized, 209 - 10, 5e-3\n",
    "# 209, 208_resized - 6, 5e-3\n",
    "# 10, 11 - 6, 5e-3\n",
    "# 108, 109 - 4, 5e-3\n",
    "# 109, 108 - 6, 5e-3\n",
    "# trees_paint, trees - 3, 5e-2\n",
    "# cows_paint, cows - 3, 5e-4\n",
    "# 309_resized, 308 - 6, 5e-3\n",
    "\n",
    "# 4_real_a, 4_real_b - 6, 5e-3\n",
    "# 4_real_b, 4_real_a - 6, 5e-2\n",
    "\n",
    "# 10_real_a, 10_real_b - 6, 5e-3\n",
    "# 10_real_b, 10_real_a - 7, 5e-3\n",
    "\n",
    "# factory_real_a, factory_real_b - 8, 5e-2\n",
    "# factory_real_b, factory_real_a - 8, 5e-3\n",
    "\n",
    "# flowers_real_a, flowers_real_b - 7, 5e-3\n",
    "# flowers_real_b, flowers_real_a - 7, 5e-3\n",
    "\n",
    "# flowers2_real_b, flowers2_real_a - 11, 5e-3\n",
    "# flowers2_real_a, flowers2_real_b - 10, 5e-3\n",
    "\n",
    "# knit_real_a, knit_real_b - 3/4, 5e-4\n",
    "# knit_real_b, knit_real_a - 6, 5e-3\n",
    "\n",
    "# perspective_real_a, perspective_real_b - 4, 5e-3\n",
    "# perspective_real_b, perspective_real_a - 8, 5e-2\n",
    "\n",
    "# snow_real_a (1), snow_real_b (2) - 5, 5e-3\n",
    "# snow_real_b (2), snow_real_a (1) - 4, 5e-2\n",
    "\n",
    "# marble_real_a, marble_real_b - 8, 5e-3\n",
    "# marble_real_b, marble_real_a - 8, 5e-3\n",
    "\n",
    "# 0_real_a, 0_real_b - 8, 5e-4\n",
    "# 0_real_b, 0_real_a - 8, 5e-4\n",
    "\n",
    "# sky_real_a, sky_real_b - 6, 5e-4\n",
    "# sky_real_b, sky_real_a - 6, 5e-4\n",
    "\n",
    "# oranges_real_a, oranges_real_b - 6, 5e-4\n",
    "# oranges_real_b, oranges_real_a - 7, 5e-4\n",
    "\n",
    "# tennis_real_a (1), tennis_real_b - 6, 5e-5\n",
    "# tennis_real_b, tennis_real_a (1) - 9, 5e-3\n",
    "\n",
    "# dirtroads_real_a, dirtroads_real_b - 7, 5e-3\n",
    "# dirtroads_real_b, dirtroads_real_a - 8, 5e-4\n",
    "\n",
    "# snow2ice_real_a, snow2ice_real_b - 10, 5e-3\n",
    "# snow2ice_real_b, snow2ice_real_a - 11, 5e-2\n",
    "\n",
    "# 22_real_a, 22_real_b - 8, 5e-4 / 10,5e-4\n",
    "# 22_real_b, 22_real_a - 7, 5e-4\n",
    "\n",
    "#### tui\n",
    "# tui_B, tui_A - 1, 5e-4 / 11, 5e-5\n",
    "# tui2_A, tui2_B - 10, 5e-2\n",
    "# tui2_B, tui2_A - 9, 5e-2 / 8, 5e-5\n",
    "images = []\n",
    "for i in range(1,26):\n",
    "    IM_PATH_B = '/home/nivg/data/NotVGAN/frames/mnist_morph/' + str(i+24) + '.png'\n",
    "    IM_PATH_A = '/home/nivg/data/NotVGAN/frames/soldiers/' + str(i) + '.png'\n",
    "    # for l in range(7,9):\n",
    "    #     for eps in ([5e0, 5e-1, 5e-2, 5e-3, 5e-4, 5e-5, 5e-6]):\n",
    "    #         print(l, eps)\n",
    "    # im = structural_analogy(IM_PATH_A, IM_PATH_B, patch_size=2, top_layer=0, eps=5e-3, print_=False)\n",
    "    im = structural_analogy_nivh(IM_PATH_A, IM_PATH_B, patch_size=7, top_layer=7, eps=1e-3, print_=False)\n",
    "    images.append(im)\n",
    "# imshow(imread(IM_PATH_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 220, 220])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3fa74ffc984465b0e30de6e4134f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xdc\\x00\\x00\\x00\\xdc\\x08\\x02\\x00\\x00\\x00\\x948X\\xd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 torch.Size([1, 3, 47, 24]) torch.Size([1, 3, 47, 47])\n",
      "7 torch.Size([1, 3, 47, 24]) torch.Size([1, 3, 47, 47])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd2e64a47d74bdca366f183dd67563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x18\\x00\\x00\\x00/\\x08\\x02\\x00\\x00\\x00vj\\x9d\\xba\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 torch.Size([1, 3, 58, 29]) torch.Size([1, 3, 58, 58])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86a62cdad4e4b25ab3482c3fb3f567f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1d\\x00\\x00\\x00:\\x08\\x02\\x00\\x00\\x00\\xc3X\\xc5\\xd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([1, 3, 73, 37]) torch.Size([1, 3, 73, 73])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e31924c65e4182b6033d0986b74091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00%\\x00\\x00\\x00I\\x08\\x02\\x00\\x00\\x005\\xcaxu\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 torch.Size([1, 3, 91, 46]) torch.Size([1, 3, 91, 91])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a66e5dc58f343a585e43986ef6f8422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00.\\x00\\x00\\x00[\\x08\\x02\\x00\\x00\\x00\\x834 \\x12\\x00\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 torch.Size([1, 3, 113, 57]) torch.Size([1, 3, 113, 113])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52bb9b911ba4731b04a5a22766d3e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x009\\x00\\x00\\x00q\\x08\\x02\\x00\\x00\\x00\\xe0q\\x9c\\xd3\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([1, 3, 141, 71]) torch.Size([1, 3, 141, 141])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2661786491004b7c8f0c3d98a54ca19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00G\\x00\\x00\\x00\\x8d\\x08\\x02\\x00\\x00\\x00j\\xa1\\xf0\\x9…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([1, 3, 176, 88]) torch.Size([1, 3, 176, 176])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcca2e202e5743f0945bddbd1f6e5b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00X\\x00\\x00\\x00\\xb0\\x08\\x02\\x00\\x00\\x00\\x04\\xe0>\\x8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 3, 220, 110]) torch.Size([1, 3, 220, 220])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc81ba4472c44c6cb3d5d8b91f8d72c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00n\\x00\\x00\\x00\\xdc\\x08\\x02\\x00\\x00\\x00\\x1e;\\x03\\xd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale 0, Total time: 3.72[s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c083ab33deb2479381ece3dfa629b8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00n\\x00\\x00\\x00\\xdc\\x08\\x02\\x00\\x00\\x00\\x1e;\\x03\\xd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plowing - 21\n",
    "# fruit - 28\n",
    "# corn - 21 \n",
    "# rome - 35\n",
    "# knitting - 35\n",
    "# farm house - 35 (large - from pyr[1:])\n",
    "# capitol - 21 (large - from pyr[1:])\n",
    "# birds - 21\n",
    "# man - 8\n",
    "# cab_building - 35\n",
    "# cake - 28\n",
    "# pantheon - 35\n",
    "# houses - 35\n",
    "# particle accelerator - 21\n",
    "# ziskind2 - 49\n",
    "# ziskind - 35\n",
    "# shirts - 21\n",
    "# lattice - 21\n",
    "# crazy-building - 42\n",
    "\n",
    "###### single step (for image expansion):\n",
    "# farm_house - 49 (from pyr[1:])\n",
    "# corn - 11 (from pyr[1:])\n",
    "# rome - 35 (from pyr[2:])\n",
    "# fruit - 21 (from pyr[0:])\n",
    "# knitting - 21 (from pyr[0:])\n",
    "# man - 7 (from pyr[0:])\n",
    "# plowing - 21 (from pyr[0:])\n",
    "# birds - 11 (from pyr[1:])\n",
    "# cab_building - 11 (from pyr[1:])\n",
    "# cake - 35 (from pyr[5:])\n",
    "# houses - 35 (from pyr[3:])\n",
    "# pantheon - 21 (from pyr[3:])\n",
    "# capitol - 14 (from pyr[2:])\n",
    "\n",
    "SUMMARY_IM_PATH = '/home/nivg/data/DropGAN/Analogies/for_assaf/marble_real_a.jpg'\n",
    "pyr = get_pyramid(SUMMARY_IM_PATH, None, 0, 20, 0.8, print_=False) \n",
    "# pyr = pyr[3:]\n",
    "print(pyr[0].shape)\n",
    "for i in range(1):\n",
    "    im, results = summarization(pyr, ratio=(1,0.5), print_=True, min_size=21, weighted_mean=True, gradual=False, eps=5e-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,im in enumerate(results):\n",
    "    ratio_h = 1**(i+1)\n",
    "    ratio_w = 0.9**(i+1)\n",
    "    save_dir = '/home/nivg/data/DropGAN/Retargeting/sunflower_%.2f_%.2f' % (ratio_h, ratio_w)\n",
    "    save_dir = save_dir.split('.')[0] + '_' + save_dir.split('.')[1] + '_' + save_dir.split('.')[2] + '.png'\n",
    "    print(save_dir)\n",
    "    imwrite(save_dir, im.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import NormalDist\n",
    "\n",
    "NormalDist(mu=0, sigma=0.85).cdf(0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage gardens + girl\n",
    "pyr1 = get_pyramid('/home/nivg/data/Tapestry_input_1.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/Tapestry_input_2.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr3 = get_pyramid('/home/nivg/data/Tapestry_input_3.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "m0 = torch.nn.ConstantPad2d((0,0,32,0),0.5)\n",
    "m1 = torch.nn.ConstantPad2d((0,0,32,0),0.66)\n",
    "m2 = torch.nn.ConstantPad2d((0,0,32,0),0.8)\n",
    "new_im = torch.cat([pyr1[0], pyr2[0], torch.cat([m0(pyr3[0][:,0,:,:]), m1(pyr3[0][:,1,:,:]), m2(pyr3[0][:,2,:,:])]).unsqueeze(0)], dim=-1)\n",
    "imshow(new_im)\n",
    "\n",
    "Montage([pyr1, pyr2, pyr3], new_im, num_steps=9, print_=False, patch_size=7, min_size=8)# with noise\n",
    "# Montage([pyr1, pyr2, pyr3], new_im, num_steps=9, print_=False, patch_size=7, min_size=21)# without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage iceland\n",
    "pyr1 = get_pyramid('/home/nivg/data/iceland_1.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/iceland_2.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr3 = get_pyramid('/home/nivg/data/iceland_3.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr1 = pyr1[3:]\n",
    "pyr2 = pyr2[3:]\n",
    "pyr3 = pyr3[3:]\n",
    "# imshow(new_im)\n",
    "new_im = torch.cat([pyr1[0], pyr2[0], pyr3[0]], dim=-1)\n",
    "Montage([pyr1, pyr2, pyr3], new_im, num_steps=9, print_=False, patch_size=7, min_size=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr1 = get_pyramid('/home/nivg/data/DropGAN/Collage/man.jpg', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/DropGAN/Collage/woman.jpg', None, 0, 15, 0.8, print_=True) # Summary\n",
    "# pyr1 = pyr1[3:]\n",
    "# pyr2 = pyr2[3:]\n",
    "# pyr3 = pyr3[3:]\n",
    "# imshow(new_im)\n",
    "\n",
    "new_im = torch.cat([pyr1[0], pyr2[0]], dim=-1)\n",
    "Montage([pyr1,pyr2], new_im, num_steps=9, print_=False, patch_size=7, min_size=7, eps=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr1 = get_pyramid('/home/nivg/data/DropGAN/Collage/rain_1.jpg', None, 0, 16, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/DropGAN/Collage/rain_2.jpg', None, 0, 16, 0.8, print_=True) # Summary\n",
    "# pyr3 = get_pyramid('/home/nivg/data/DropGAN/Collage/children3.jpg', None, 0, 16, 0.8, print_=True) # Summary\n",
    "\n",
    "# pyr2 = pyr2[1:]\n",
    "# pyr2 = pyr2[3:]\n",
    "# pyr3 = pyr3[3:]\n",
    "# imshow(new_im)\n",
    "m0 = torch.nn.ConstantPad2d((0,0,44,0),0)\n",
    "m1 = torch.nn.ConstantPad2d((0,0,44,0),0)\n",
    "m2 = torch.nn.ConstantPad2d((0,0,44,0),1)\n",
    "\n",
    "new_im = torch.cat([pyr2[0], pyr1[0]], dim=-1)\n",
    "# new_im = torch.cat([pyr1[0], torch.cat([m0(pyr2[0][:,0,:,:]), m1(pyr2[0][:,1,:,:]), m2(pyr2[0][:,2,:,:])]).unsqueeze(0)], dim=-1)\n",
    "imshow(new_im)\n",
    "Montage([pyr3,pyr1,pyr2], new_im, num_steps=9, print_=False, patch_size=7, min_size=21, eps=5e-3, noise_std=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyr1 = get_pyramid('/home/nivg/data/DropGAN/Collage/f1.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr2 = get_pyramid('/home/nivg/data/DropGAN/Collage/f2.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "pyr3 = get_pyramid('/home/nivg/data/DropGAN/Collage/f3.png', None, 0, 15, 0.8, print_=True) # Summary\n",
    "\n",
    "pyr1 = pyr1[1:]\n",
    "pyr2 = pyr2[1:]\n",
    "pyr3 = pyr3[1:]\n",
    "\n",
    "new_im = torch.cat([pyr1[0], pyr2[0], pyr3[0]], dim=-1)\n",
    "imshow(new_im)\n",
    "Montage([pyr1, pyr2, pyr3], new_im, num_steps=9, print_=False, patch_size=7, min_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Conditional Inpainting\n",
    "# pyr = get_pyramid('/home/nivg/data/204.jpg', None, 0, 15,0.75)\n",
    "# mask = torch.ones_like(pyr[0])\n",
    "# mask[:,:,50:75, 20:40] = 0\n",
    "# new_im = pyr[0].clone()\n",
    "# for i in range(3):\n",
    "#     if i == 2:\n",
    "#         new_im[:,i,50:75, 20:40] = 0\n",
    "#     else:\n",
    "#         new_im[:,i,50:75, 20:40] = 1\n",
    "# conditional_inpainting(new_im, mask, patch_size=7, top_layer=5, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/BSDS100/296007.png', None, 0, 15,0.75)\n",
    "pyr = pyr[2:]\n",
    "mask = torch.ones_like(pyr[0])\n",
    "# mask[:,:,140:165, 160:190] = 0\n",
    "mask[:,:,80:120, 10:120] = 0\n",
    "\n",
    "new_im = pyr[0].clone()#*mask\n",
    "imshow(new_im)\n",
    "for i in range(1):\n",
    "    if i == 0:\n",
    "#         new_im[:,:,140:165, 160:190] = 1.0\n",
    "        \n",
    "#         for j in range(3):\n",
    "#             if j == 1:\n",
    "#                 new_im[:,j,140:165, 160:190] = 0.7\n",
    "#             else:\n",
    "#                 new_im[:,j,140:165, 160:190] = 0\n",
    "        \n",
    "        for j in range(3):\n",
    "            if j == 1:\n",
    "                new_im[:,j,80:120, 10:120] = 0.7\n",
    "            else:\n",
    "                new_im[:,j,80:120, 10:120] = 0\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for j in range(3):\n",
    "            if j < 2:\n",
    "                new_im[:,j,140:165, 160:190] = 0.7\n",
    "            else:\n",
    "                new_im[:,j,140:165, 160:190] = 0.3\n",
    "    conditional_inpainting(new_im, mask, patch_size=7, top_layer=6, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/DropGAN/potential_new_inputs/checkers.jpg', None, 0, 15,0.75, False)\n",
    "mask = torch.ones_like(pyr[0])\n",
    "mask[:,:,120:135, 50:70] = 0\n",
    "new_im = pyr[0].clone()*mask\n",
    "imshow(new_im)\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        new_im[:,:,120:135, 50:70] = 0.0\n",
    "    else:\n",
    "        new_im[:,:,120:135, 50:70] = 1\n",
    "    conditional_inpainting(new_im, mask, patch_size=7, top_layer=6, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/DropGAN/Analogies/for_assaf/marble_real_a.jpg', None, 0, 15,0.75, False)\n",
    "mask = torch.ones_like(pyr[0])\n",
    "mask[:,:,170:220, 10:50] = 0\n",
    "new_im = pyr[0].clone()*mask\n",
    "imshow(new_im)\n",
    "for i in range(3):\n",
    "    if i == 0:\n",
    "        for j in range(3):\n",
    "            if j == 2:\n",
    "                new_im[:,j,170:220, 10:50] = 1\n",
    "            else:\n",
    "                new_im[:,j,170:220, 10:50] = 0\n",
    "    elif i == 1:\n",
    "        for j in range(3):\n",
    "            if j == 1:\n",
    "                new_im[:,j,170:220, 10:50] = 1\n",
    "            else:\n",
    "                new_im[:,j,170:220, 10:50] = 0\n",
    "    else:\n",
    "        for j in range(3):\n",
    "            if j == 2:\n",
    "                new_im[:,j,170:220, 10:50] = 0.9\n",
    "            elif j == 1:\n",
    "                new_im[:,j,170:220, 10:50] = 0.5\n",
    "            else:\n",
    "                new_im[:,j,170:220, 10:50] = 0\n",
    "\n",
    "    new_im = conditional_inpainting(new_im, mask, patch_size=7, top_layer=6, print_=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/fruit.png', None, 0, 15,0.75, False)\n",
    "mask = torch.ones_like(pyr[0])\n",
    "mask[:,:,105:120, 125:165] = 0\n",
    "new_im = pyr[0].clone()*mask\n",
    "imshow(new_im)\n",
    "for i in range(3):\n",
    "    if i == 0:\n",
    "        for j in range(3):\n",
    "            if j == 0:\n",
    "                new_im[:,j,105:120, 125:165] = 1\n",
    "            else:\n",
    "                new_im[:,j,105:120, 125:165] = 0\n",
    "    elif i == 1:\n",
    "        for j in range(3):\n",
    "            if j == 2:\n",
    "                new_im[:,j,105:120, 125:165] = 0\n",
    "            else:\n",
    "                new_im[:,j,105:120, 125:165] = 1\n",
    "    else:\n",
    "        for j in range(3):\n",
    "            if j == 2:\n",
    "                new_im[:,j,105:120, 125:165] = 0.9\n",
    "            elif j == 1:\n",
    "                new_im[:,j,105:120, 125:165] = 0.\n",
    "            else:\n",
    "                new_im[:,j,105:120, 125:165] = 0\n",
    "\n",
    "    conditional_inpainting(new_im, mask, patch_size=7, top_layer=3, print_=False)\n",
    "#     new_im = conditional_inpainting(new_im, mask, patch_size=7, top_layer=4, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conditional Inpainting for figure\n",
    "pyr = get_pyramid('/home/nivg/data/DropGAN/Conditional_inpainting/library.png', None, 0, 15,0.75, False)\n",
    "\n",
    "mask = get_pyramid('/home/nivg/data/DropGAN/Conditional_inpainting/library_mask.png', None, 0, 15,0.75, False)\n",
    "mask = mask[3]\n",
    "imshow(mask)\n",
    "# mask[:,:,105:120, 125:165] = 0\n",
    "new_im = pyr[3].clone()*mask\n",
    "new_im[(1-mask).byte()] = torch.randn_like(pyr[3])[(1-mask).byte()] + 0.5\n",
    "print(new_im.shape)\n",
    "imshow(new_im)\n",
    "for i in range(1):\n",
    "#     if i == 0:\n",
    "#         for j in range(3):\n",
    "#             if j == 0:\n",
    "#                 new_im[:,j,105:120, 125:165] = 1\n",
    "#             else:\n",
    "#                 new_im[:,j,105:120, 125:165] = 0\n",
    "#     elif i == 1:\n",
    "#         for j in range(3):\n",
    "#             if j == 2:\n",
    "#                 new_im[:,j,105:120, 125:165] = 0\n",
    "#             else:\n",
    "#                 new_im[:,j,105:120, 125:165] = 1\n",
    "#     else:\n",
    "#         for j in range(3):\n",
    "#             if j == 2:\n",
    "#                 new_im[:,j,105:120, 125:165] = 0.9\n",
    "#             elif j == 1:\n",
    "#                 new_im[:,j,105:120, 125:165] = 0.\n",
    "#             else:\n",
    "#                 new_im[:,j,105:120, 125:165] = 0\n",
    "\n",
    "#     conditional_inpainting(new_im, mask, patch_size=7, top_layer=6, print_=False)\n",
    "    new_im = conditional_inpainting(new_im, mask, patch_size=4, top_layer=5, print_=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### figure 4 (PNN) \n",
    "orig_pyr = get_pyramid('/home/nivg/data/balloons.png', None, 0, 15,0.75)\n",
    "pyr = get_pyramid('/home/nivg/data/DropGAN/balloons_for_figure.png', None, 0, 15,0.75)\n",
    "\n",
    "unfold = torch.nn.Unfold(kernel_size=(29,29))\n",
    "imshow(pyr[3])\n",
    "rsizer = Resizer.Resizer(pyr[5].shape, (4/3)**2, pyr[3].shape).cuda()\n",
    "imshow(rsizer(pyr[5]))\n",
    "imshow(rsizer(orig_pyr[5]))\n",
    "imshow(orig_pyr[3])\n",
    "q_patches = unfold(rsizer(pyr[5]))\n",
    "k_patches = unfold(rsizer(orig_pyr[5]))\n",
    "v_patches = unfold(orig_pyr[3])\n",
    "print(in_patches.shape[-1])\n",
    "for i in range(q_patches.shape[-1]):\n",
    "    if i % 10 == 1:\n",
    "        print(i)\n",
    "        imshow(q_patches[:,:,i].reshape(1,3,29,29))\n",
    "        imshow(k_patches[:,:,i].reshape(1,3,29,29))\n",
    "        imshow(v_patches[:,:,i].reshape(1,3,29,29))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIFID\n",
    "\n",
    "\n",
    "SIFID_REAL_DIR = '/home/nivg/data/DropGAN/user_study/real/'\n",
    "files = os.listdir(SIFID_REAL_DIR)\n",
    "for file in files:\n",
    "    if file.split('.')[1] == 'jpg':\n",
    "        print(file)\n",
    "        pyr = get_pyramid(SIFID_REAL_DIR + file, None, 0, 15, 0.75, print_=False) \n",
    "        for ratio in ([[1,1]]):\n",
    "            rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "            dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "            for k in range(5):\n",
    "                im = new_image_generation(pyr, dst_pyr)\n",
    "                imshow(torch.cat([im, pyr[0], np2pt(imread('/home/nivg/data/DropGAN/user_study/fake_mid_variance/' + file)).cuda()], dim=-1))\n",
    "                print(get_psnr(im, pyr[0]))\n",
    "#                 imwrite('/home/nivg/data/DropGAN/user_study/fake_DropGAN_std_1_25/' + file.split('.')[0] + '.png', im.squeeze(0).detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIFID\n",
    "\n",
    "SIFID_REAL_DIR = '/home/nivg/data/DropGAN/user_study/real/'\n",
    "files = os.listdir(SIFID_REAL_DIR)\n",
    "count = 0\n",
    "for file in files:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    if file.split('.')[1] == 'jpg':\n",
    "        pyr = get_pyramid(SIFID_REAL_DIR + file, None, 0, 15, 0.75, print_=False) \n",
    "        for ratio in ([[1,1]]):\n",
    "            rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "            dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "            for k in range(50):\n",
    "                print(k)\n",
    "                im = new_image_generation(pyr, dst_pyr)\n",
    "                print(get_psnr(im, pyr[0]))\n",
    "                imwrite('/home/nivg/data/DropGAN/user_study/fake_DropGAN_variability_std_1_25_test_png/' + 'repeat_' + str(k) + '_' + file.split('.')[0] + '.png', im.squeeze(0).detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIFID new DS\n",
    "\n",
    "SIFID_REAL_DIR = '/home/nivg/data/DropGAN/user_study/newDS_jpg/'\n",
    "files = os.listdir(SIFID_REAL_DIR)\n",
    "count = 0\n",
    "for file in files:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    if file in ['vietnam_traffic.jpg']:\n",
    "        pyr = get_pyramid(SIFID_REAL_DIR + file, None, 0, 15, 0.75, print_=False) \n",
    "        for ratio in ([[1,1]]):\n",
    "            rsizer = Resizer.Resizer(pyr[0].shape, ratio).cuda()\n",
    "            dst_pyr = get_pyramids_aux(rsizer(pyr[0]), num_layers=15, ratio=3/4, print_=False)\n",
    "            for k in range(50):\n",
    "                print(k)\n",
    "                im = new_image_generation(pyr, dst_pyr)\n",
    "                print(get_psnr(im, pyr[0]))\n",
    "                imwrite('/home/nivg/data/DropGAN/user_study/fake_DropGAN_variability_std_0_75_new_DS/' + file.split('.')[0] + '/' +  str(k) + '.png', im.squeeze(0).detach().cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5,10)\n",
    "ind = torch.randint(low=0, high=10, size=(5,))\n",
    "print(a)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for unconditional figure\n",
    "BASE_PATH = '/home/nivg/data/'\n",
    "pyr = get_pyramid(BASE_PATH + 'carrots_s.png', None, 0, 15, 0.75, print_=False)\n",
    "pyr=pyr[1:]\n",
    "images = []\n",
    "noisy = []\n",
    "for i in range(50):\n",
    "    n = torch.randn_like(pyr[9])*0.75\n",
    "    new_im = build_image_weighted(pyr[9] + n, [pyr[9]] ,[pyr[9]], patch_size=7)\n",
    "    imshow(pyr[9]+n)\n",
    "#     print(new_im.shape)\n",
    "    noises.append(n) \n",
    "#     images.append(new_im) \n",
    "    new_im *= 255\n",
    "    images.append(new_im.detach().clone().squeeze(0).permute(1,2,0).cpu().type(torch.uint8))\n",
    "    \n",
    "#     noise = (n.clone() + 1)*255/2\n",
    "    noisy.append((255*(pyr[9] + n)).detach().clone().squeeze(0).permute(1,2,0).cpu().type(torch.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_write = {'fps':4.0, 'quantizer':'nq'}\n",
    "imageio.mimsave('/home/nivg/data/YouTube/noise.gif',noisy[1::2],'GIF-FI', **kwargs_write)\n",
    "# print(noises[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.plugins.freeimage.download()\n",
    "kwargs_write = {'fps':1.0, 'quantizer':'nq'}\n",
    "\n",
    "folder = '/home/nivg/data/DropGAN/user_study/fake_DropGAN_variability_std_0_75_new_DS/balloons/'\n",
    "gt = np.expand_dims(imread('/home/nivg/data/DropGAN/user_study/newDS_jpg/people_on_the_beach.jpg'),0)\n",
    "gt = torch.tensor(gt).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "images = []\n",
    "for file in os.listdir(folder):\n",
    "    im = np.expand_dims(imread(folder + file),0)\n",
    "    im = torch.tensor(im).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "    im *= 255\n",
    "#     if get_psnr(im,gt) <= 35:\n",
    "    images.append(im.detach().clone().squeeze(0).permute(1,2,0).cpu().type(torch.uint8))\n",
    "imageio.mimsave('/home/nivg/data/DropGAN/balloons.gif',images,'GIF-FI', **kwargs_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "folder = '/home/nivg/data/DropGAN/user_study/fake_DropGAN_variability_std_1_25_test_png/'\n",
    "gt = np.expand_dims(imread('/home/nivg/data/DropGAN/user_study/real/8.jpg'),0)\n",
    "gt = torch.tensor(gt).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "images = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith('_8.png'): \n",
    "        im = np.expand_dims(imread(folder + file),0)\n",
    "        im = torch.tensor(im).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "#         if get_psnr(im,gt) <= 35:\n",
    "        images.append(im.detach().clone().squeeze(0).permute(1,2,0).cpu())\n",
    "imageio.mimsave('/home/nivg/data/DropGAN/8.gif',images,'GIF-FI', **kwargs_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "for i in ['8']:\n",
    "    folder = '/home/nivg/Projects/SinGAN/Output/RandomSamples/' + str(i) + '/gen_start_scale=0/'\n",
    "#     gt = np.expand_dims(imread('/home/nivg/data/DropGAN/user_study/newDS_jpg/people_on_the_beach.jpg'),0)\n",
    "#     gt = torch.tensor(gt).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "    images = []\n",
    "    for file in os.listdir(folder):\n",
    "        im = np.expand_dims(imread(folder + file),0)\n",
    "        im = torch.tensor(im).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "#         if get_psnr(im,gt) <= 35:\n",
    "        images.append(im.detach().clone().squeeze(0).permute(1,2,0).cpu())\n",
    "    imageio.mimsave('/home/nivg/data/DropGAN/' + str(i) + '_singan.gif',images,'GIF-FI', **kwargs_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "folder = '/home/nivg/data/DropGAN/user_study/newDS_jpg/'\n",
    "sg_folder = '/home/nivg/data/DropGAN/user_study/fake_SinGAN_newDS_level_N/RandomSamples/'\n",
    "dg_folder = '/home/nivg/data/DropGAN/user_study/fake_DropGAN_variability_std_0_75_new_DS/'\n",
    "kwargs_write = {'fps':1.0, 'quantizer':'nq'}\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "#     gt = np.expand_dims(imread('/home/nivg/data/DropGAN/user_study/newDS_jpg/' + file),0)\n",
    "#     gt = torch.tensor(gt).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "    sg_images = []\n",
    "    dg_images = []\n",
    "    for l in range(50):\n",
    "        sg_im = np.expand_dims(imread(sg_folder + file.split('.')[0] + '/' + 'gen_start_scale=0/' + str(l) + '.png'),0)\n",
    "        sg_im = torch.tensor(sg_im).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "        sg_im *= 255\n",
    "        sg_images.append(sg_im.detach().clone().squeeze(0).permute(1,2,0).cpu().type(torch.uint8))\n",
    "        dg_im = np.expand_dims(imread(dg_folder + file.split('.')[0] + '/' + str(l) + '.png'),0)\n",
    "        dg_im = torch.tensor(dg_im).contiguous().permute(0,3,1,2).detach().cuda()\n",
    "        dg_im *= 255\n",
    "        dg_images.append(dg_im.detach().clone().squeeze(0).permute(1,2,0).cpu().type(torch.uint8))\n",
    "\n",
    "#         if get_psnr(im,gt) <= 35:\n",
    "#             images.append(im.detach().clone().squeeze(0).permute(1,2,0).cpu())\n",
    "    imageio.mimsave('/home/nivg/data/DropGAN/supp/' + file.split('.')[0] + '_sg.gif', sg_images, 'GIF-FI', **kwargs_write)\n",
    "    imageio.mimsave('/home/nivg/data/DropGAN/supp/' + file.split('.')[0] + '_dg.gif',dg_images,'GIF-FI', **kwargs_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"/home/nivg/data/DropGAN/template.txt\", \"r\")\n",
    "# txt = f.read()\n",
    "\n",
    "# folder = '/home/nivg/data/DropGAN/user_study/newDS_jpg/'\n",
    "# new_txt = \"\"\n",
    "# new_file = \"\"\n",
    "# for file in os.listdir(folder):\n",
    "#     new_txt = txt.replace(\"method_010\", \"method_\" + file.split('.')[0])\n",
    "#     new_txt = new_txt.replace(\"010_rand_ker\", file.split('.')[0])\n",
    "#     new_txt = new_txt.replace(\"bicubic\", \"source\")\n",
    "#     new_txt = new_txt.replace(\"edsr\", \"GPNN\")\n",
    "#     new_txt = new_txt.replace(\"michaeli\", \"SinGAN\")\n",
    "#     new_txt = new_txt.replace(\"psnr_007\", \"measures_\" + file.split('.')[0])\n",
    "#     new_txt = new_txt.replace(\"psnr_010\", \"measures_\" + file.split('.')[0])\n",
    "#     new_txt = new_txt.replace(\"birds_3.jpg\", file)\n",
    "# #     print(new_txt)\n",
    "#     new_file = new_file + new_txt + '\\n'\n",
    "# print(new_file)\n",
    "\n",
    "f = open(\"/home/nivg/data/DropGAN/template2.txt\", \"r\")\n",
    "txt = f.read()\n",
    "\n",
    "folder = '/home/nivg/data/DropGAN/user_study/newDS_jpg/'\n",
    "new_txt = \"\"\n",
    "new_file = \"\"\n",
    "files = os.listdir(folder)\n",
    "for i in range(0,len(files),2):\n",
    "    file = files[i]\n",
    "    print(file)\n",
    "    new_txt = txt.replace(\"method_dolphins\", \"method_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"dolphins\", file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"measures_dolphins\", \"measures_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"measures_dolphins\", \"measures_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"dolphins.jpg\", file)\n",
    "    file = files[i+1]\n",
    "    print(file)\n",
    "    new_txt = new_txt.replace(\"method_208\", \"method_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"208\", file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"measures_208\", \"measures_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"measures_208\", \"measures_\" + file.split('.')[0])\n",
    "    new_txt = new_txt.replace(\"208.jpg\", file)\n",
    "\n",
    "#     print(new_txt)\n",
    "    new_file = new_file + new_txt + '\\n'\n",
    "# print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = \"\"\"3.jpg\n",
    "# 18.jpg\n",
    "# 44.jpg\n",
    "# 8.jpg\n",
    "# 34.jpg\n",
    "# 25.jpg\n",
    "# 10.jpg\n",
    "# 35.jpg\n",
    "# 36.jpg\n",
    "# 30.jpg\n",
    "# 48.jpg\n",
    "# 11.jpg\n",
    "# 12.jpg\n",
    "# 43.jpg\n",
    "# 21.jpg\n",
    "# 13.jpg\n",
    "# 1.jpg\n",
    "# 39.jpg\n",
    "# 2.jpg\n",
    "# 5.jpg\n",
    "# 33.jpg\n",
    "# 46.jpg\n",
    "# 50.jpg\n",
    "# 19.jpg\n",
    "# 40.jpg\n",
    "# 47.jpg\n",
    "# 49.jpg\n",
    "# 16.jpg\n",
    "# 31.jpg\n",
    "# 9.jpg\n",
    "# 26.jpg\n",
    "# 6.jpg\n",
    "# 37.jpg\n",
    "# 42.jpg\n",
    "# 17.jpg\n",
    "# 32.jpg\n",
    "# 4.jpg\n",
    "# 24.jpg\n",
    "# 27.jpg\n",
    "# 38.jpg\n",
    "# 28.jpg\n",
    "# 14.jpg\n",
    "# 45.jpg\n",
    "# 29.jpg\n",
    "# 7.jpg\n",
    "# 22.jpg\n",
    "# 23.jpg\n",
    "# 41.jpg\n",
    "# 15.jpg\n",
    "# 20.jpg\"\"\".strip().split()\n",
    "# files = [f.strip() for f in files if f.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"\"\"3.jpg\n",
    "18.jpg\n",
    "44.jpg\n",
    "8.jpg\n",
    "25.jpg\n",
    "10.jpg\n",
    "36.jpg\n",
    "48.jpg\n",
    "11.jpg\n",
    "12.jpg\n",
    "21.jpg\n",
    "13.jpg\n",
    "1.jpg\n",
    "39.jpg\n",
    "5.jpg\n",
    "33.jpg\n",
    "46.jpg\n",
    "19.jpg\n",
    "40.jpg\n",
    "49.jpg\n",
    "16.jpg\n",
    "31.jpg\n",
    "26.jpg\n",
    "6.jpg\n",
    "37.jpg\n",
    "42.jpg\n",
    "23.jpg\n",
    "17.jpg\n",
    "32.jpg\n",
    "41.jpg\n",
    "4.jpg\n",
    "15.jpg\n",
    "24.jpg\n",
    "27.jpg\n",
    "38.jpg\n",
    "20.jpg\n",
    "28.jpg\n",
    "14.jpg\n",
    "45.jpg\n",
    "29.jpg\n",
    "7.jpg\n",
    "22.jpg\n",
    "2.jpg\n",
    "50.jpg\n",
    "47.jpg\n",
    "9.jpg\n",
    "43.jpg\n",
    "30.jpg\n",
    "35.jpg\n",
    "34.jpg\n",
    "\"\"\".strip().split()\n",
    "files = [f.strip() for f in files if f.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/nivg/data/DropGAN/template2.txt\", \"r\") as f:\n",
    "    txt = f.read()\n",
    "# flag = '_mv'\n",
    "flag = ''\n",
    "folder = '/home/nivg/data/DropGAN/user_study/real/'\n",
    "new_txt = \"\"\n",
    "new_file = \"\"\n",
    "# files = os.listdir(folder)\n",
    "for i in range(0,len(files),2):\n",
    "    file = files[i]\n",
    "    print(file)\n",
    "    new_txt = txt.replace(\"method_dolphins\", \"method_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"sigd_gt/dolphins.jpg\", \"places_gt/\" + file)\n",
    "    new_txt = new_txt.replace(\"dolphins\", file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"measures_dolphins\", \"measures_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"measures_dolphins\", \"measures_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"dolphins.jpg\", file)\n",
    "    new_txt = new_txt.replace(file.split('.')[0] + flag + '.jpg', file.split('.')[0] + '.jpg')\n",
    "    file = files[i+1]\n",
    "    print(file)\n",
    "    new_txt = new_txt.replace(\"method_208\", \"method_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"sigd_gt/208.jpg\", \"places_gt/\" + file)\n",
    "    new_txt = new_txt.replace(\"208\", file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"measures_208\", \"measures_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"measures_208\", \"measures_\" + file.split('.')[0] + flag)\n",
    "    new_txt = new_txt.replace(\"208.jpg\", file)\n",
    "    new_txt = new_txt.replace(\"sigd_gt\", \"places_gt\")\n",
    "    new_txt = new_txt.replace(\"sigd_dg\", \"places_dg\" + flag)\n",
    "    new_txt = new_txt.replace(\"sigd_sg\", \"places_sg\" + flag)\n",
    "    new_txt = new_txt.replace(\"_GPNN\", \"_GPNN\" + flag)\n",
    "    new_txt = new_txt.replace(\"_source\", \"_source\" + flag)\n",
    "    new_txt = new_txt.replace(\"_SinGAN\", \"_SinGAN\" + flag)\n",
    "    new_txt = new_txt.replace(file.split('.')[0] + flag + '.jpg', file.split('.')[0] + '.jpg')\n",
    "#     print(new_txt)\n",
    "    new_file = new_file + new_txt + '\\n'\n",
    "# print(new_file)\n",
    "\n",
    "with open(\"/home/nivg/data/DropGAN/sigd_html_places\" + flag + \"_new.txt\", \"w\") as f:\n",
    "    f.write(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"\"\"3.jpg\n",
    "18.jpg\n",
    "44.jpg\n",
    "8.jpg\n",
    "34.jpg\n",
    "25.jpg\n",
    "10.jpg\n",
    "35.jpg\n",
    "36.jpg\n",
    "30.jpg\n",
    "48.jpg\n",
    "11.jpg\n",
    "12.jpg\n",
    "43.jpg\n",
    "21.jpg\n",
    "13.jpg\n",
    "1.jpg\n",
    "39.jpg\n",
    "2.jpg\n",
    "5.jpg\n",
    "33.jpg\n",
    "46.jpg\n",
    "50.jpg\n",
    "19.jpg\n",
    "40.jpg\n",
    "47.jpg\n",
    "49.jpg\n",
    "16.jpg\n",
    "31.jpg\n",
    "9.jpg\n",
    "26.jpg\n",
    "6.jpg\n",
    "37.jpg\n",
    "42.jpg\n",
    "17.jpg\n",
    "32.jpg\n",
    "4.jpg\n",
    "24.jpg\n",
    "27.jpg\n",
    "38.jpg\n",
    "28.jpg\n",
    "14.jpg\n",
    "45.jpg\n",
    "29.jpg\n",
    "7.jpg\n",
    "22.jpg\n",
    "23.jpg\n",
    "41.jpg\n",
    "15.jpg\n",
    "20.jpg\"\"\".strip().split()\n",
    "files = [f.strip() for f in files if f.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt.replace(\"places_gt/dolphins\", \"places_gt/ashdaz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
