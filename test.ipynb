{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat -cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch._C._jit_set_profiling_executor(False)\n",
    "torch._C._jit_set_profiling_mode(False)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.utils import _pair\n",
    "from typing import Tuple\n",
    "\n",
    "#@torch.jit.script\n",
    "def unfold2d(x: torch.Tensor, kernel_size: Tuple[int, int], stride: Tuple[int, int] = (1, 1)):\n",
    "    # type: (torch.Tensor, Tuple[int, int], Tuple[int, int]) -> torch.Tensor\n",
    "    kernel_size = _pair(kernel_size)\n",
    "    stride = _pair(stride)\n",
    "    padding = ((kernel_size[1] - 1) // 2, kernel_size[1] // 2, (kernel_size[0] - 1) // 2, kernel_size[0] // 2)\n",
    "\n",
    "    x = F.pad(x, pad=padding)\n",
    "    return x.unfold(2, kernel_size[0], stride[0]).unfold(3, kernel_size[1], stride[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold2d.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "# def l2_norm_2d(x, y):\n",
    "#     return (x - y).pow(2).sum(1)\n",
    "\n",
    "# @torch.jit.script\n",
    "# def l2_norm_2d_(qs, ks, rs, i, j, t):\n",
    "#     # type: (torch.Tensor, torch.Tensor, torch.Tensor, int, int, int) -> int\n",
    "#     rs[t] = l2_norm_2d(qs, ks[..., i, j])\n",
    "#     return 0\n",
    "\n",
    "# @torch.jit.script\n",
    "# def local_argmin(qs, ks):\n",
    "#     N, C, H, W, h, w = ks.size()\n",
    "#     futures : List[torch.jit.Future[int]] = []\n",
    "#     results = qs.new_zeros(size=(h * w, N, H, W))\n",
    "#     for i in range(h):\n",
    "#         for j in range(w):\n",
    "#             futures.append(torch.jit.fork(l2_norm_2d_, qs, ks, results, i, j, i * w + j))\n",
    "    \n",
    "# #     results = []\n",
    "#     for future in futures:\n",
    "#         torch.jit.wait(future)\n",
    "# #         results.append(torch.jit.wait(future))\n",
    "\n",
    "# #     results = torch.stack(results, dim=0)\n",
    "\n",
    "#     argmin = results.argmin(0)\n",
    "# #     return argmin\n",
    "#     return torch.stack([argmin // w, argmin % w], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "# # @torch.jit.script\n",
    "# def pll2_norm_2d(x, y):\n",
    "# #     dxy = x - y\n",
    "# #     return torch.einsum('nchw,nchw->nhw', dxy, dxy)\n",
    "#     return (x - y).pow(2).sum(1)\n",
    "\n",
    "# def parallel_local_argmin_(qs, ks, rs, t1, t2):\n",
    "#     # type: (torch.Tensor, torch.Tensor, torch.Tensor, int, int) -> int\n",
    "#     # qs: NCHW\n",
    "#     # ks: NCHWhw\n",
    "#     N, C, H, W, h, w = ks.size()\n",
    "# #     results = qs.new_zeros(size=(t2 - t1, N, H, W))\n",
    "#     for t in range(t1, t2):\n",
    "#         i, j = t // w, t % w\n",
    "#         rs[t] = ll2_norm_2d(qs, ks[..., i, j])\n",
    "#     return 0\n",
    "# #     argmin = results.argmin(0)\n",
    "# #     return torch.stack([argmin // w, argmin % w], dim=-1)\n",
    "\n",
    "# @torch.jit.script\n",
    "# def parallel_local_argmin(qs, ks, split=1):\n",
    "#     # type: (torch.Tensor, torch.Tensor, int) -> torch.Tensor\n",
    "#     # qs: NCHW\n",
    "#     # ks: NCHWhw\n",
    "#     N, C, H, W, h, w = ks.size()\n",
    "#     T = h * w\n",
    "#     results = qs.new_zeros(size=(T, N, H, W))\n",
    "#     futures : List[torch.jit.Future[int]] = []\n",
    "#     dt = (T + split - 1) // split\n",
    "#     for t1 in range(0, T, dt):\n",
    "#         t2 = min(T - 1, t1 + dt)\n",
    "#         futures.append(torch.jit.fork(parallel_local_argmin_, qs, ks, results, t1, t2))\n",
    "    \n",
    "# #     results = []\n",
    "#     for future in futures:\n",
    "#         torch.jit.wait(future)\n",
    "# #         results.append(torch.jit.wait(future))\n",
    "# #     results = torch.cat(results, dim=0)\n",
    "#     argmin = results.argmin(0)\n",
    "#     return torch.stack([argmin // w, argmin % w], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsz = 31\n",
    "# with torch.no_grad():\n",
    "#     qs = torch.randn(size=(1, 75, 256, 256), device=DEVICE)\n",
    "#     ks = torch.randn_like(qs)\n",
    "#     ks = unfold2d(ks, (lsz, lsz))\n",
    "\n",
    "# # local_argmin_jit = torch.jit.optimized_execution(local_argmin, (qs, ks))\n",
    "    \n",
    "# start.record()\n",
    "# with torch.no_grad():\n",
    "#     r = parallel_local_argmin(qs, ks)\n",
    "# end.record()\n",
    "# torch.cuda.synchronize()\n",
    "# print(start.elapsed_time(end))\n",
    "\n",
    "# # r = local_argmin(qs, ks)\n",
    "# !nvidia-smi -i $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def ll2_norm_2d(x, y):\n",
    "#     dxy = x - y\n",
    "#     return torch.einsum('nchw,nchw->nhw', dxy, dxy)\n",
    "    return (x - y).pow(2).sum(1)\n",
    "\n",
    "# @torch.jit.script\n",
    "def local_argmin(qs, ks):\n",
    "    # qs: NCHW\n",
    "    # ks: NCHWhw\n",
    "    N, C, H, W, h, w = ks.size()\n",
    "#     results = qs.new_zeros(size=(h * w, N, H, W))\n",
    "    results: List[torch.Tensor] = []\n",
    "    for t in range(h * w):\n",
    "        i = t // w\n",
    "        j = t % w\n",
    "#         results[t] = ll2_norm_2d(qs, ks[..., i, j]) # .pow(2).sum(1)\n",
    "        results.append(ll2_norm_2d(qs, ks[..., i, j])) # .pow(2).sum(1)\n",
    "#     for i in range(h):\n",
    "#         for j in range(w):\n",
    "#             t = i * w + j\n",
    "#             results.append((qs - ks[..., i, j]).pow(2).sum(1))  # ll2_norm_2d(qs, ks[..., i, j]))\n",
    "#             results[i, j] = ll2_norm_2d(qs, ks[..., i, j])\n",
    "#             results[t] = (qs - ks[..., i, j]).pow(2).sum(1)\n",
    "    results = torch.stack(results, dim=0)\n",
    "#     results = results.view(h * w, N, H, W)\n",
    "    argmin = results.argmin(0)\n",
    "#     return argmin\n",
    "    return torch.stack([argmin // w, argmin % w], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def ll2_norm_2d(x, y):\n",
    "#     dxy = x - y\n",
    "#     return torch.einsum('nchw,nchw->nhw', dxy, dxy)\n",
    "    return (x - y).pow(2).sum(1)\n",
    "\n",
    "# @torch.jit.script\n",
    "def local_argmin(qs, ks):\n",
    "    # qs: NCHW\n",
    "    # ks: NCHWhw\n",
    "    N, C, H, W, h, w = ks.size()\n",
    "    results = qs.new_zeros(size=(h * w, N, H, W))\n",
    "#     results: List[torch.Tensor] = []\n",
    "    for t in range(h * w):\n",
    "        i = t // w\n",
    "        j = t % w\n",
    "        results[t] = ll2_norm_2d(qs, ks[..., i, j]) # .pow(2).sum(1)\n",
    "#         results.append(ll2_norm_2d(qs, ks[..., i, j])) # .pow(2).sum(1)\n",
    "#     for i in range(h):\n",
    "#         for j in range(w):\n",
    "#             t = i * w + j\n",
    "#             results.append((qs - ks[..., i, j]).pow(2).sum(1))  # ll2_norm_2d(qs, ks[..., i, j]))\n",
    "#             results[i, j] = ll2_norm_2d(qs, ks[..., i, j])\n",
    "#             results[t] = (qs - ks[..., i, j]).pow(2).sum(1)\n",
    "#     results = torch.stack(results, dim=0)\n",
    "#     results = results.view(h * w, N, H, W)\n",
    "    argmin = results.argmin(0)\n",
    "#     return argmin\n",
    "    return torch.stack([argmin // w, argmin % w], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_argmin.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsz = 31\n",
    "with torch.no_grad():\n",
    "    qs = torch.randn(size=(10, 147, 256, 256), device=DEVICE)\n",
    "    ks = torch.randn_like(qs)\n",
    "    ks = unfold2d(ks, (lsz, lsz))\n",
    "\n",
    "# local_argmin_jit = torch.jit.optimized_execution(local_argmin, (qs, ks))\n",
    "    \n",
    "start.record()\n",
    "with torch.no_grad():\n",
    "    r = local_argmin(qs, ks)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "\n",
    "# r = local_argmin(qs, ks)\n",
    "!nvidia-smi -i $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def gl2_norm_2d(x, y):\n",
    "    xx = torch.einsum('nchw,nchw->nhw', x, x).unsqueeze(-1).unsqueeze(-1)\n",
    "    yy = torch.einsum('ncij,ncij->nij', y, y).unsqueeze(1).unsqueeze(1)\n",
    "    xy = torch.einsum('nchw,ncij->nhwij', x, y)\n",
    "    return xx + yy - 2 * xy\n",
    "\n",
    "# @torch.jit.script\n",
    "def global_argmin(qs, ks, max_size=2**28):\n",
    "    # qs: NCHW\n",
    "    # ks: NCIJ\n",
    "    N, C, H, W = ks.size()\n",
    "    _, _, I, J = qs.size()\n",
    "    dist_mat = gl2_norm_2d(qs, ks)  # torch.einsum('nchw,ncij->nhwij', qs, ks)\n",
    "    dist_mat = dist_mat.view(N, H * W, I, J)\n",
    "    argmin = dist_mat.argmin(1)\n",
    "    return torch.stack([argmin // W, argmin % W], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def gl2_norm_2d(x, y):\n",
    "    # print(x.shape, y.shape)\n",
    "    xx = torch.einsum('nic,nic->ni', x, x).unsqueeze(2)\n",
    "    yy = torch.einsum('njc,njc->nj', y, y).unsqueeze(1)\n",
    "    xy = torch.einsum('nic,njc->nij', x, y)\n",
    "    return xx + yy - 2 * xy\n",
    "\n",
    "@torch.jit.script\n",
    "def global_argmin(qs, ks):\n",
    "    # qs: NCHW\n",
    "    # ks: NCIJ\n",
    "    max_size = 2**28\n",
    "    N, C, H, W = ks.size()\n",
    "    _, _, I, J = qs.size()\n",
    "    qs = qs.permute(0, 2, 3, 1).contiguous().view(N, I * J, C)\n",
    "    ks = ks.permute(0, 2, 3, 1).contiguous().view(N, H * W, C)\n",
    "    nq, nk = I * J, H * W\n",
    "    max_size = int((max_size + N - 1) // N)\n",
    "    bq = int((max_size + nk - 1) // (nk))\n",
    "    idxs = []\n",
    "    # print(qs)\n",
    "    for j in range(int((nq + bq - 1) // bq)):\n",
    "        dist_mat = gl2_norm_2d(ks, qs[:, j*bq:(j+1)*bq])\n",
    "        dist_mat = dist_mat.view(N, H * W, -1)\n",
    "        idxs.append(dist_mat.argmin(1))\n",
    "    idxs = torch.cat(idxs, dim=-1).view(N, I, J)\n",
    "    return torch.stack([idxs // W, idxs % W], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    qs = torch.randn(size=(10, 147, 256, 256), device=DEVICE)\n",
    "    ks = torch.randn(size=(10, 147, 256, 256), device=DEVICE)\n",
    "\n",
    "start.record()\n",
    "with torch.no_grad():\n",
    "    r = global_argmin(qs, ks)  # , max_size=2**29)\n",
    "end.record()\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "\n",
    "# r = local_argmin(qs, ks)\n",
    "!nvidia-smi -i $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
