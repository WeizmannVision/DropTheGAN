{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mn103.mcl11.weizmann.ac.il\u001b[m  Mon Jan  4 19:38:16 2021  \u001b[1m\u001b[30m418.87.00\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce RTX 2080 Ti\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m10989\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat -cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold2d(input, kernel_size):\n",
    "    if input.dim() != 4:\n",
    "        raise ValueError('expected 4D tensor as input.')\n",
    "    n, c, h, w = input.size()\n",
    "    kh, kw = kernel_size = _pair(kernel_size)\n",
    "    ph, pw = padding = (kh - 1, kw - 1)\n",
    "    oh, ow = h + 2 * ph - kh + 1, w + 2 * pw - kw + 1\n",
    "    output = F.unfold(input, kernel_size, padding=padding)\n",
    "    output = output.view(n, c, kh, kw, oh, ow)\n",
    "    return output\n",
    "\n",
    "\n",
    "def fold2d(input, reduce='sum', std=1.7):\n",
    "    if input.dim() != 6:\n",
    "        raise ValueError('expected 6D tensor as input.')\n",
    "    n, c, kh, kw, h, w = input.shape\n",
    "    if reduce == 'sum':\n",
    "        output = _fold2d_sum(input)\n",
    "    elif reduce == 'mean':\n",
    "        weights = _get_weights_fold2d_mean(input, kh, kw)\n",
    "        output = _fold2d_sum(input)\n",
    "        norm = weights.sum()\n",
    "        output = output / norm\n",
    "    elif reduce == 'weighted_mean':\n",
    "        weights = _get_weights_fold2d_weighted_mean(input, kh, kw, std)\n",
    "        output = _fold2d_sum(input * weights)\n",
    "        norm = weights.sum()\n",
    "        output = output / norm\n",
    "    elif reduce == 'median':\n",
    "        output = _fold2d_median(input)\n",
    "    else:\n",
    "        raise ValueError(f'unknown reduction: {reduce}')\n",
    "    return output\n",
    "\n",
    "\n",
    "def _fold2d_sum(input):\n",
    "    if input.dim() != 6:\n",
    "        raise ValueError('expected 6D tensor as input.')\n",
    "    n, c, kh, kw, h, w = input.shape\n",
    "    ph, pw = padding = (kh - 1, kw - 1)\n",
    "    oh, ow = output_size = (h + kh - 1 - 2 * ph, w + kw - 1 - 2 * pw)\n",
    "    kernel_size = (kh, kw)\n",
    "    input = input.reshape(n, c * kh * kw, h * w)\n",
    "    output = F.fold(input, output_size, kernel_size, padding=padding)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _fold2d_median(input):\n",
    "    if input.dim() != 6:\n",
    "        raise ValueError('expected 6D tensor as input.')\n",
    "    n, c, kh, kw, h, w = input.shape\n",
    "    ph, pw = (kh - 1, kw - 1)\n",
    "    oh, ow = (h + kh - 1 - 2 * ph, w + kw - 1 - 2 * pw)\n",
    "    output = input.new_zeros(size=(kh * kw, n, c, oh, ow))\n",
    "    for i in range(kh):\n",
    "        for j in range(kw):\n",
    "            output[i * kw + j] = input[:, :, i, j, kh - 1 - i:h - i, kw - 1 - j:w - j]  # noqa\n",
    "    output = output.median(dim=0)[0]\n",
    "    return output\n",
    "\n",
    "\n",
    "def _get_weights_fold2d_mean(input, kh, kw):\n",
    "    weights = input.new_ones(size=(kh, kw))\n",
    "    return weights.view(1, 1, kh, kw, 1, 1)\n",
    "\n",
    "\n",
    "def _get_weights_fold2d_weighted_mean(input, kh, kw, std):\n",
    "    to = {'device': input.device, 'dtype': input.dtype}\n",
    "    gh = torch.linspace(-1, 1, kh, **to)\n",
    "    gw = torch.linspace(-1, 1, kw, **to)\n",
    "    nh = torch.exp(-0.5 * (gh / std).pow(2))\n",
    "    nw = torch.exp(-0.5 * (gw / std).pow(2))\n",
    "    weights = torch.einsum('i,j->ij', nh, nw)\n",
    "    return weights.view(1, 1, kh, kw, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (2, 2)\n",
    "x = 10 * torch.rand(size=(10, 3, 100, 100), device=DEVICE)\n",
    "y = unfold2d(x, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6042879819869995\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    z1 = fold2d(y, reduce='sum')\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1708159446716309\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    z2 = fold2d(y, reduce='mean')\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end))\n",
    "    assert torch.allclose(x, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0504000186920166\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    z3 = fold2d(y, reduce='weighted_mean')\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.095359802246094\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start.record()\n",
    "    z4 = fold2d(y, reduce='median')\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    print(start.elapsed_time(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.allclose(x, z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
